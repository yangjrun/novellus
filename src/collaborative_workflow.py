"""
äººå·¥AIåä½œåˆ›ä½œå·¥ä½œæµç³»ç»Ÿ
æ”¯æŒç”¨æˆ·æ‰‹åŠ¨ä¸AIäº¤äº’çš„åˆ›ä½œæ¨¡å¼
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
import json
import uuid
import asyncio
from pathlib import Path

from database.data_access import get_novel_manager
from prompt_generator.core import NovelPromptGenerator


class SessionStatus(Enum):
    """ä¼šè¯çŠ¶æ€"""
    ACTIVE = "active"
    COMPLETED = "completed"
    PAUSED = "paused"
    ABANDONED = "abandoned"


class ContentType(Enum):
    """å†…å®¹ç±»å‹"""
    SCENE = "scene"
    DIALOGUE = "dialogue"
    ACTION = "action"
    DESCRIPTION = "description"
    TRANSITION = "transition"
    CHAPTER_OPENING = "chapter_opening"
    CHAPTER_ENDING = "chapter_ending"
    BREAKTHROUGH = "breakthrough"


@dataclass
class PromptComponents:
    """Promptç»„ä»¶"""
    system_prompt: str
    user_prompt: str
    suggested_max_tokens: int = 2000
    suggested_temperature: float = 0.8
    model_recommendation: str = "Claude 3.5 Sonnet"
    parameters: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AnalysisResult:
    """åˆ†æç»“æœ"""
    # åŸºç¡€è´¨é‡æŒ‡æ ‡
    length_analysis: Dict[str, Any]
    structure_analysis: Dict[str, Any]
    character_consistency: Dict[str, Any]
    world_consistency: Dict[str, Any]

    # åˆ›ä½œè´¨é‡è¯„ä¼°
    narrative_flow: Dict[str, Any]
    dialogue_quality: Dict[str, Any]
    scene_vividness: Dict[str, Any]
    emotional_impact: Dict[str, Any]

    # æ³•åˆ™é“¾ç³»ç»Ÿç¬¦åˆåº¦
    law_chain_accuracy: Dict[str, Any]
    power_system_consistency: Dict[str, Any]

    # æ”¹è¿›å»ºè®®
    strengths: List[str]
    weaknesses: List[str]
    specific_suggestions: List[str]
    prompt_optimization_tips: List[str]

    # æ€»ä½“è¯„åˆ†
    overall_score: float = 0.0
    recommendation: str = ""


@dataclass
class CreationSession:
    """åˆ›ä½œä¼šè¯"""
    session_id: str
    novel_id: str
    chapter_number: int
    created_at: datetime
    session_name: str = ""

    # Promptç›¸å…³
    original_prompt: Optional[PromptComponents] = None
    prompt_iterations: List[PromptComponents] = field(default_factory=list)

    # å†…å®¹ç›¸å…³
    generated_contents: List[str] = field(default_factory=list)
    user_ratings: List[int] = field(default_factory=list)
    analysis_results: List[AnalysisResult] = field(default_factory=list)

    # æœ€ç»ˆç»“æœ
    final_content: Optional[str] = None
    session_notes: str = ""
    status: SessionStatus = SessionStatus.ACTIVE

    # ç»Ÿè®¡ä¿¡æ¯
    iteration_count: int = 0
    total_time_minutes: float = 0.0
    best_iteration_index: Optional[int] = None


class ContentAnalyzer:
    """å†…å®¹åˆ†æå™¨"""

    def __init__(self, db_manager):
        self.db_manager = db_manager

    def _analyze_length(self, content: str) -> Dict[str, Any]:
        """åˆ†æå†…å®¹é•¿åº¦"""
        words = content.split()
        sentences = content.split('ã€‚')
        paragraphs = content.split('\n\n')

        return {
            "character_count": len(content),
            "word_count": len(words),
            "sentence_count": len(sentences),
            "paragraph_count": len(paragraphs),
            "avg_sentence_length": len(words) / max(len(sentences), 1),
            "avg_paragraph_length": len(words) / max(len(paragraphs), 1)
        }

    def _analyze_structure(self, content: str) -> Dict[str, Any]:
        """åˆ†æå†…å®¹ç»“æ„"""
        has_dialogue = '"' in content or '"' in content
        has_action = any(word in content for word in ['è·ƒèµ·', 'å‡ºæ‰‹', 'æ”»å‡»', 'èº²é¿', 'æ–½å±•'])
        has_description = any(word in content for word in ['å¤©ç©º', 'å¤§åœ°', 'æ™¯è‰²', 'ç¯å¢ƒ'])

        # æ®µè½ç±»å‹åˆ†æ
        paragraphs = content.split('\n\n')
        dialogue_paragraphs = sum(1 for p in paragraphs if '"' in p or '"' in p)
        action_paragraphs = sum(1 for p in paragraphs if any(w in p for w in ['è·ƒèµ·', 'å‡ºæ‰‹', 'æ”»å‡»']))

        return {
            "has_dialogue": has_dialogue,
            "has_action": has_action,
            "has_description": has_description,
            "dialogue_ratio": dialogue_paragraphs / max(len(paragraphs), 1),
            "action_ratio": action_paragraphs / max(len(paragraphs), 1),
            "paragraph_types": {
                "total": len(paragraphs),
                "dialogue": dialogue_paragraphs,
                "action": action_paragraphs,
                "mixed": len(paragraphs) - dialogue_paragraphs - action_paragraphs
            }
        }

    def _check_character_consistency(self, content: str, characters: List[str] = None) -> Dict[str, Any]:
        """æ£€æŸ¥è§’è‰²ä¸€è‡´æ€§"""
        issues = []
        character_mentions = {}

        if characters:
            for char in characters:
                count = content.count(char)
                character_mentions[char] = count
                if count == 0:
                    issues.append(f"è§’è‰² {char} æœªå‡ºç°åœ¨å†…å®¹ä¸­")

        return {
            "character_mentions": character_mentions,
            "consistency_issues": issues,
            "is_consistent": len(issues) == 0
        }

    def _check_world_consistency(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥ä¸–ç•Œè§‚ä¸€è‡´æ€§"""
        # æ£€æŸ¥æ³•åˆ™é“¾ç›¸å…³æœ¯è¯­
        law_chain_terms = ['æ³•åˆ™é“¾', 'æ³•åˆ™ä¹‹åŠ›', 'æŒæ§è€…', 'å…±é¸£', 'æ³•åˆ™ç©ºé—´']
        power_terms = ['å¢ƒç•Œ', 'çªç ´', 'ç“¶é¢ˆ', 'æ„Ÿæ‚Ÿ']

        found_terms = {
            "law_chain": [term for term in law_chain_terms if term in content],
            "power_system": [term for term in power_terms if term in content]
        }

        return {
            "found_world_terms": found_terms,
            "law_chain_mentioned": len(found_terms["law_chain"]) > 0,
            "power_system_mentioned": len(found_terms["power_system"]) > 0
        }

    def _evaluate_narrative_flow(self, content: str) -> Dict[str, Any]:
        """è¯„ä¼°å™äº‹æµç•…åº¦"""
        # æ£€æŸ¥è¿‡æ¸¡è¯
        transition_words = ['ç„¶è€Œ', 'ä½†æ˜¯', 'éšå', 'æ¥ç€', 'ä¸æ­¤åŒæ—¶', 'çªç„¶', 'æ¸æ¸']
        transitions_found = sum(1 for word in transition_words if word in content)

        # æ£€æŸ¥æ—¶é—´æ ‡è®°
        time_markers = ['ç‰‡åˆ»', 'ç¬é—´', 'è®¸ä¹…', 'ä¸ä¹…', 'æ­¤æ—¶', 'å½“ä¸‹']
        time_markers_found = sum(1 for marker in time_markers if marker in content)

        return {
            "transition_count": transitions_found,
            "time_markers_count": time_markers_found,
            "flow_score": min((transitions_found + time_markers_found) / 10, 1.0),
            "has_good_flow": transitions_found >= 2
        }

    def _evaluate_dialogue(self, content: str) -> Dict[str, Any]:
        """è¯„ä¼°å¯¹è¯è´¨é‡"""
        import re

        # æå–å¯¹è¯
        dialogues = re.findall(r'[""](.*?)["""]', content)

        if not dialogues:
            return {
                "dialogue_count": 0,
                "avg_dialogue_length": 0,
                "quality_score": 0,
                "issues": ["æ— å¯¹è¯å†…å®¹"]
            }

        avg_length = sum(len(d) for d in dialogues) / len(dialogues)

        # æ£€æŸ¥å¯¹è¯å¤šæ ·æ€§
        unique_starters = len(set(d.split('ï¼Œ')[0] if 'ï¼Œ' in d else d[:10] for d in dialogues))
        diversity_score = unique_starters / len(dialogues)

        return {
            "dialogue_count": len(dialogues),
            "avg_dialogue_length": avg_length,
            "diversity_score": diversity_score,
            "quality_score": diversity_score * 0.7 + min(avg_length / 50, 1.0) * 0.3,
            "issues": []
        }

    def _evaluate_scene_description(self, content: str) -> Dict[str, Any]:
        """è¯„ä¼°åœºæ™¯æå†™"""
        # æ„Ÿå®˜è¯æ±‡
        visual_words = ['çœ‹è§', 'ç¥è§', 'æ³¨è§†', 'è‰²å½©', 'å…‰èŠ’', 'é˜´å½±', 'æ˜äº®', 'é»‘æš—']
        auditory_words = ['å¬åˆ°', 'å£°éŸ³', 'è½°é¸£', 'ä½è¯­', 'å›å“', 'å¯‚é™']
        tactile_words = ['è§¦æ‘¸', 'æ„Ÿå—', 'å†°å†·', 'æ¸©æš–', 'ç²—ç³™', 'å…‰æ»‘']

        visual_count = sum(1 for word in visual_words if word in content)
        auditory_count = sum(1 for word in auditory_words if word in content)
        tactile_count = sum(1 for word in tactile_words if word in content)

        sensory_richness = (visual_count + auditory_count + tactile_count) / 15

        return {
            "visual_elements": visual_count,
            "auditory_elements": auditory_count,
            "tactile_elements": tactile_count,
            "sensory_richness_score": min(sensory_richness, 1.0),
            "is_vivid": sensory_richness > 0.3
        }

    def _evaluate_emotional_impact(self, content: str) -> Dict[str, Any]:
        """è¯„ä¼°æƒ…æ„Ÿå†²å‡»åŠ›"""
        # æƒ…æ„Ÿè¯æ±‡
        emotion_words = {
            "positive": ['å–œæ‚¦', 'å…´å¥‹', 'æ¬£æ…°', 'æ»¡è¶³', 'è‡ªè±ª', 'å¸Œæœ›'],
            "negative": ['æ„¤æ€’', 'æ‚²ä¼¤', 'ç»æœ›', 'ææƒ§', 'ç„¦è™‘', 'å¤±æœ›'],
            "intense": ['éœ‡æ’¼', 'æƒŠéª‡', 'ç‹‚å–œ', 'å´©æºƒ', 'ç–¯ç‹‚', 'æè‡´']
        }

        emotion_counts = {}
        for category, words in emotion_words.items():
            emotion_counts[category] = sum(1 for word in words if word in content)

        total_emotions = sum(emotion_counts.values())
        intensity = emotion_counts.get("intense", 0) / max(total_emotions, 1)

        return {
            "emotion_counts": emotion_counts,
            "total_emotions": total_emotions,
            "emotional_intensity": intensity,
            "impact_score": min(total_emotions / 10, 1.0) * 0.7 + intensity * 0.3
        }

    def _check_law_chain_usage(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥æ³•åˆ™é“¾ç³»ç»Ÿä½¿ç”¨"""
        # æ³•åˆ™é“¾ç›¸å…³æ£€æŸ¥
        law_chains = ['æ—¶é—´', 'ç©ºé—´', 'ç”Ÿå‘½', 'æ­»äº¡', 'å› æœ', 'è½®å›', 'åˆ›é€ ', 'æ¯ç­', 'å¹³è¡¡']
        mentioned_chains = [chain for chain in law_chains if chain in content and 'æ³•åˆ™' in content]

        # æ£€æŸ¥æ³•åˆ™é“¾æè¿°çš„å‡†ç¡®æ€§
        accuracy_issues = []
        if 'æ—¶é—´æ³•åˆ™' in content and 'ç©ºé—´' not in content:
            accuracy_issues.append("æ—¶é—´æ³•åˆ™é€šå¸¸ä¸ç©ºé—´æ³•åˆ™ç›¸å…³è”")

        return {
            "mentioned_law_chains": mentioned_chains,
            "chain_count": len(mentioned_chains),
            "accuracy_issues": accuracy_issues,
            "usage_score": min(len(mentioned_chains) / 3, 1.0)
        }

    def _check_power_system(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥åŠ›é‡ä½“ç³»ä¸€è‡´æ€§"""
        # å¢ƒç•Œç›¸å…³
        realms = ['å‡¡äºº', 'ç­‘åŸº', 'é‡‘ä¸¹', 'å…ƒå©´', 'åŒ–ç¥', 'åˆä½“', 'æ¸¡åŠ«', 'å¤§ä¹˜', 'æŒæ§è€…']
        mentioned_realms = [realm for realm in realms if realm in content]

        # æ£€æŸ¥å¢ƒç•Œæè¿°çš„é€»è¾‘æ€§
        consistency_issues = []
        realm_indices = {realm: i for i, realm in enumerate(realms)}

        if len(mentioned_realms) > 1:
            indices = [realm_indices[r] for r in mentioned_realms]
            if max(indices) - min(indices) > 3:
                consistency_issues.append("å¢ƒç•Œè·¨åº¦è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨é€»è¾‘é—®é¢˜")

        return {
            "mentioned_realms": mentioned_realms,
            "consistency_issues": consistency_issues,
            "is_consistent": len(consistency_issues) == 0
        }

    async def comprehensive_analysis(
        self,
        content: str,
        prompt_used: Optional[PromptComponents] = None,
        world_context: Dict = None,
        user_expectations: Dict = None,
        focus_characters: List[str] = None
    ) -> AnalysisResult:
        """å…¨é¢åˆ†æç”Ÿæˆå†…å®¹"""

        # æ‰§è¡Œå„é¡¹åˆ†æ
        length_analysis = self._analyze_length(content)
        structure_analysis = self._analyze_structure(content)
        character_consistency = self._check_character_consistency(content, focus_characters)
        world_consistency = self._check_world_consistency(content)
        narrative_flow = self._evaluate_narrative_flow(content)
        dialogue_quality = self._evaluate_dialogue(content)
        scene_vividness = self._evaluate_scene_description(content)
        emotional_impact = self._evaluate_emotional_impact(content)
        law_chain_accuracy = self._check_law_chain_usage(content)
        power_system_consistency = self._check_power_system(content)

        # æ”¶é›†ä¼˜ç‚¹
        strengths = []
        if narrative_flow["has_good_flow"]:
            strengths.append("å™äº‹æµç•…ï¼Œè¿‡æ¸¡è‡ªç„¶")
        if dialogue_quality.get("quality_score", 0) > 0.7:
            strengths.append("å¯¹è¯ç”ŸåŠ¨ï¼Œå¯Œæœ‰ä¸ªæ€§")
        if scene_vividness["is_vivid"]:
            strengths.append("åœºæ™¯æå†™ç»†è…»ï¼Œæ„Ÿå®˜ä¸°å¯Œ")
        if law_chain_accuracy["chain_count"] > 0:
            strengths.append("æ³•åˆ™é“¾ç³»ç»Ÿè¿ç”¨å¾—å½“")

        # æ”¶é›†ç¼ºç‚¹
        weaknesses = []
        if not narrative_flow["has_good_flow"]:
            weaknesses.append("å™äº‹ç¼ºå°‘è¿‡æ¸¡ï¼Œæ˜¾å¾—ç”Ÿç¡¬")
        if dialogue_quality.get("quality_score", 0) < 0.5:
            weaknesses.append("å¯¹è¯è´¨é‡æœ‰å¾…æå‡")
        if not scene_vividness["is_vivid"]:
            weaknesses.append("åœºæ™¯æå†™ä¸å¤Ÿç”ŸåŠ¨")
        if character_consistency["consistency_issues"]:
            weaknesses.extend(character_consistency["consistency_issues"])

        # ç”Ÿæˆå…·ä½“å»ºè®®
        specific_suggestions = []
        if narrative_flow["transition_count"] < 2:
            specific_suggestions.append("å¢åŠ è¿‡æ¸¡è¯å’Œæ—¶é—´æ ‡è®°ï¼Œè®©å™äº‹æ›´æµç•…")
        if dialogue_quality.get("dialogue_count", 0) < 3:
            specific_suggestions.append("é€‚å½“å¢åŠ å¯¹è¯ï¼Œè®©è§’è‰²æ›´ç«‹ä½“")
        if scene_vividness["sensory_richness_score"] < 0.3:
            specific_suggestions.append("åŠ å…¥æ›´å¤šæ„Ÿå®˜æå†™ï¼Œå¦‚è§†è§‰ã€å¬è§‰ã€è§¦è§‰ç­‰")
        if law_chain_accuracy["chain_count"] == 0:
            specific_suggestions.append("è€ƒè™‘åŠ å…¥æ³•åˆ™é“¾ç›¸å…³çš„æè¿°ï¼Œå¢å¼ºä¸–ç•Œè§‚ç‰¹è‰²")

        # Promptä¼˜åŒ–å»ºè®®
        prompt_optimization_tips = []
        if length_analysis["word_count"] < 500:
            prompt_optimization_tips.append("åœ¨promptä¸­æ˜ç¡®è¦æ±‚æ›´è¯¦ç»†çš„æå†™")
        if not dialogue_quality.get("dialogue_count"):
            prompt_optimization_tips.append("åœ¨promptä¸­è¦æ±‚åŒ…å«è§’è‰²å¯¹è¯")
        if not law_chain_accuracy["mentioned_law_chains"]:
            prompt_optimization_tips.append("åœ¨promptä¸­æé†’AIå…³æ³¨æ³•åˆ™é“¾ç³»ç»Ÿ")

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        scores = [
            narrative_flow.get("flow_score", 0) * 0.2,
            dialogue_quality.get("quality_score", 0) * 0.2,
            scene_vividness.get("sensory_richness_score", 0) * 0.15,
            emotional_impact.get("impact_score", 0) * 0.15,
            law_chain_accuracy.get("usage_score", 0) * 0.15,
            (1.0 if power_system_consistency["is_consistent"] else 0.5) * 0.15
        ]
        overall_score = sum(scores)

        # ç”Ÿæˆæ¨è
        if overall_score > 0.8:
            recommendation = "ä¼˜ç§€ï¼å¯ä»¥ç›´æ¥ä½¿ç”¨æˆ–ç¨ä½œæ¶¦è‰²"
        elif overall_score > 0.6:
            recommendation = "è‰¯å¥½ï¼Œå»ºè®®æ ¹æ®å…·ä½“å»ºè®®è¿›è¡Œä¼˜åŒ–"
        elif overall_score > 0.4:
            recommendation = "ä¸€èˆ¬ï¼Œéœ€è¦è¾ƒå¤§å¹…åº¦çš„æ”¹è¿›"
        else:
            recommendation = "éœ€è¦é‡æ–°ç”Ÿæˆæˆ–å¤§å¹…ä¿®æ”¹"

        return AnalysisResult(
            length_analysis=length_analysis,
            structure_analysis=structure_analysis,
            character_consistency=character_consistency,
            world_consistency=world_consistency,
            narrative_flow=narrative_flow,
            dialogue_quality=dialogue_quality,
            scene_vividness=scene_vividness,
            emotional_impact=emotional_impact,
            law_chain_accuracy=law_chain_accuracy,
            power_system_consistency=power_system_consistency,
            strengths=strengths,
            weaknesses=weaknesses,
            specific_suggestions=specific_suggestions,
            prompt_optimization_tips=prompt_optimization_tips,
            overall_score=overall_score,
            recommendation=recommendation
        )


class CreationSessionManager:
    """åˆ›ä½œä¼šè¯ç®¡ç†å™¨"""

    def __init__(self, db_manager):
        self.db_manager = db_manager
        self.sessions: Dict[str, CreationSession] = {}
        self.session_storage_path = Path("creation_sessions")
        self.session_storage_path.mkdir(exist_ok=True)

    async def create_session(
        self,
        novel_id: str,
        chapter_number: int,
        session_name: str = ""
    ) -> str:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session_id = str(uuid.uuid4())

        if not session_name:
            session_name = f"ç¬¬{chapter_number}ç« åˆ›ä½œä¼šè¯_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        session = CreationSession(
            session_id=session_id,
            novel_id=novel_id,
            chapter_number=chapter_number,
            created_at=datetime.now(),
            session_name=session_name
        )

        self.sessions[session_id] = session
        await self._save_session(session)

        return session_id

    async def add_content_iteration(
        self,
        session_id: str,
        content: str,
        user_rating: int,
        analysis: AnalysisResult,
        prompt_used: Optional[PromptComponents] = None
    ):
        """æ·»åŠ å†…å®¹è¿­ä»£"""
        if session_id not in self.sessions:
            raise ValueError(f"Session {session_id} not found")

        session = self.sessions[session_id]
        session.generated_contents.append(content)
        session.user_ratings.append(user_rating)
        session.analysis_results.append(analysis)

        if prompt_used:
            session.prompt_iterations.append(prompt_used)

        session.iteration_count += 1

        # æ›´æ–°æœ€ä½³è¿­ä»£
        if user_rating >= 8 or (session.best_iteration_index is None):
            if session.best_iteration_index is None or user_rating > session.user_ratings[session.best_iteration_index]:
                session.best_iteration_index = len(session.user_ratings) - 1

        await self._save_session(session)

    async def get_session(self, session_id: str) -> Optional[CreationSession]:
        """è·å–ä¼šè¯"""
        if session_id in self.sessions:
            return self.sessions[session_id]

        # å°è¯•ä»å­˜å‚¨åŠ è½½
        session_file = self.session_storage_path / f"{session_id}.json"
        if session_file.exists():
            return await self._load_session(session_id)

        return None

    async def update_session_status(
        self,
        session_id: str,
        status: SessionStatus,
        final_content: Optional[str] = None,
        notes: str = ""
    ):
        """æ›´æ–°ä¼šè¯çŠ¶æ€"""
        if session_id not in self.sessions:
            raise ValueError(f"Session {session_id} not found")

        session = self.sessions[session_id]
        session.status = status

        if final_content:
            session.final_content = final_content

        if notes:
            session.session_notes = notes

        if status == SessionStatus.COMPLETED:
            session.total_time_minutes = (
                datetime.now() - session.created_at
            ).total_seconds() / 60

        await self._save_session(session)

    async def get_session_statistics(self, session_id: str) -> Dict:
        """è·å–ä¼šè¯ç»Ÿè®¡"""
        session = await self.get_session(session_id)
        if not session:
            return {}

        stats = {
            "session_id": session.session_id,
            "session_name": session.session_name,
            "novel_id": session.novel_id,
            "chapter_number": session.chapter_number,
            "status": session.status.value,
            "created_at": session.created_at.isoformat(),
            "iteration_count": session.iteration_count,
            "total_time_minutes": session.total_time_minutes,
            "average_rating": sum(session.user_ratings) / len(session.user_ratings) if session.user_ratings else 0,
            "best_rating": max(session.user_ratings) if session.user_ratings else 0,
            "best_iteration_index": session.best_iteration_index,
            "has_final_content": session.final_content is not None,
            "overall_scores": [r.overall_score for r in session.analysis_results],
            "improvement_trend": self._calculate_improvement_trend(session)
        }

        return stats

    def _calculate_improvement_trend(self, session: CreationSession) -> str:
        """è®¡ç®—æ”¹è¿›è¶‹åŠ¿"""
        if len(session.user_ratings) < 2:
            return "insufficient_data"

        # æ¯”è¾ƒå‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†çš„å¹³å‡è¯„åˆ†
        mid = len(session.user_ratings) // 2
        first_half_avg = sum(session.user_ratings[:mid]) / mid
        second_half_avg = sum(session.user_ratings[mid:]) / (len(session.user_ratings) - mid)

        if second_half_avg > first_half_avg + 0.5:
            return "improving"
        elif second_half_avg < first_half_avg - 0.5:
            return "declining"
        else:
            return "stable"

    async def _save_session(self, session: CreationSession):
        """ä¿å­˜ä¼šè¯åˆ°æ–‡ä»¶"""
        session_file = self.session_storage_path / f"{session.session_id}.json"

        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        session_data = {
            "session_id": session.session_id,
            "novel_id": session.novel_id,
            "chapter_number": session.chapter_number,
            "created_at": session.created_at.isoformat(),
            "session_name": session.session_name,
            "status": session.status.value,
            "iteration_count": session.iteration_count,
            "total_time_minutes": session.total_time_minutes,
            "best_iteration_index": session.best_iteration_index,
            "generated_contents": session.generated_contents,
            "user_ratings": session.user_ratings,
            "final_content": session.final_content,
            "session_notes": session.session_notes
        }

        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)

    async def _load_session(self, session_id: str) -> Optional[CreationSession]:
        """ä»æ–‡ä»¶åŠ è½½ä¼šè¯"""
        session_file = self.session_storage_path / f"{session_id}.json"

        if not session_file.exists():
            return None

        with open(session_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # é‡å»ºä¼šè¯å¯¹è±¡
        session = CreationSession(
            session_id=data["session_id"],
            novel_id=data["novel_id"],
            chapter_number=data["chapter_number"],
            created_at=datetime.fromisoformat(data["created_at"]),
            session_name=data["session_name"],
            status=SessionStatus(data["status"]),
            iteration_count=data["iteration_count"],
            total_time_minutes=data["total_time_minutes"],
            best_iteration_index=data["best_iteration_index"],
            generated_contents=data["generated_contents"],
            user_ratings=data["user_ratings"],
            final_content=data["final_content"],
            session_notes=data["session_notes"]
        )

        self.sessions[session_id] = session
        return session


class UserInteractionInterface:
    """ç”¨æˆ·äº¤äº’ç•Œé¢"""

    def format_prompt_for_display(self, prompt_components: PromptComponents) -> str:
        """æ ¼å¼åŒ–promptä¾›ç”¨æˆ·å¤åˆ¶"""
        divider = "=" * 50

        formatted = f"""
{divider}
Novellus åˆ›ä½œæç¤ºè¯
{divider}

ã€ç³»ç»Ÿæç¤ºè¯ / System Promptã€‘
{'-' * 40}
{prompt_components.system_prompt}

ã€ç”¨æˆ·æç¤ºè¯ / User Promptã€‘
{'-' * 40}
{prompt_components.user_prompt}

ã€å‚æ•°å»ºè®® / Suggested Parametersã€‘
{'-' * 40}
â€¢ æœ€å¤§Tokenæ•°: {prompt_components.suggested_max_tokens}
â€¢ æ¸©åº¦å‚æ•°: {prompt_components.suggested_temperature}
â€¢ æ¨èæ¨¡å‹: {prompt_components.model_recommendation}

ã€ä½¿ç”¨è¯´æ˜ / Instructionsã€‘
{'-' * 40}
1. å°†ã€ç³»ç»Ÿæç¤ºè¯ã€‘å¤åˆ¶åˆ°Claudeçš„Systemå­—æ®µï¼ˆå¦‚æœå¯ç”¨ï¼‰
2. å°†ã€ç”¨æˆ·æç¤ºè¯ã€‘å¤åˆ¶åˆ°å¯¹è¯æ¡†
3. æŒ‰ç…§å‚æ•°å»ºè®®è®¾ç½®AIå‚æ•°
4. ç”Ÿæˆå†…å®¹åï¼Œå°†ç»“æœè¿”å›ç»™Novellusè¿›è¡Œåˆ†æ

ã€å¿«é€Ÿå¤åˆ¶åŒºã€‘
{'-' * 40}
å®Œæ•´æç¤ºè¯ï¼ˆå¯ç›´æ¥ç²˜è´´ï¼‰:

{prompt_components.system_prompt}

{prompt_components.user_prompt}
{divider}
"""
        return formatted

    def format_analysis_report(self, analysis: AnalysisResult) -> str:
        """æ ¼å¼åŒ–åˆ†ææŠ¥å‘Š"""
        divider = "=" * 50
        sub_divider = "-" * 40

        # ç”Ÿæˆæ˜Ÿçº§è¯„åˆ†
        stars = "â˜…" * int(analysis.overall_score * 5) + "â˜†" * (5 - int(analysis.overall_score * 5))

        report = f"""
{divider}
Novellus å†…å®¹åˆ†ææŠ¥å‘Š
{divider}

ã€æ€»ä½“è¯„åˆ†ã€‘ {stars} ({analysis.overall_score:.2f}/1.00)
ã€æ¨èå»ºè®®ã€‘ {analysis.recommendation}

{sub_divider}
ã€è´¨é‡æŒ‡æ ‡ã€‘
{sub_divider}
â€¢ å™äº‹æµç•…åº¦: {self._score_to_bar(analysis.narrative_flow.get('flow_score', 0))}
â€¢ å¯¹è¯è´¨é‡: {self._score_to_bar(analysis.dialogue_quality.get('quality_score', 0))}
â€¢ åœºæ™¯ç”ŸåŠ¨æ€§: {self._score_to_bar(analysis.scene_vividness.get('sensory_richness_score', 0))}
â€¢ æƒ…æ„Ÿå†²å‡»åŠ›: {self._score_to_bar(analysis.emotional_impact.get('impact_score', 0))}
â€¢ æ³•åˆ™é“¾å‡†ç¡®æ€§: {self._score_to_bar(analysis.law_chain_accuracy.get('usage_score', 0))}

{sub_divider}
ã€å†…å®¹ç»Ÿè®¡ã€‘
{sub_divider}
â€¢ æ€»å­—æ•°: {analysis.length_analysis['character_count']} å­—
â€¢ æ®µè½æ•°: {analysis.length_analysis['paragraph_count']} æ®µ
â€¢ å¯¹è¯æ•°: {analysis.dialogue_quality.get('dialogue_count', 0)} å¤„
â€¢ æ³•åˆ™é“¾æåŠ: {', '.join(analysis.law_chain_accuracy['mentioned_law_chains']) if analysis.law_chain_accuracy['mentioned_law_chains'] else 'æ— '}

{sub_divider}
ã€ä¼˜ç‚¹ã€‘ âœ“
{sub_divider}
"""
        for strength in analysis.strengths:
            report += f"â€¢ {strength}\n"

        report += f"""
{sub_divider}
ã€å¾…æ”¹è¿›ã€‘ âš 
{sub_divider}
"""
        for weakness in analysis.weaknesses:
            report += f"â€¢ {weakness}\n"

        report += f"""
{sub_divider}
ã€å…·ä½“å»ºè®®ã€‘ ğŸ’¡
{sub_divider}
"""
        for i, suggestion in enumerate(analysis.specific_suggestions, 1):
            report += f"{i}. {suggestion}\n"

        if analysis.prompt_optimization_tips:
            report += f"""
{sub_divider}
ã€Promptä¼˜åŒ–å»ºè®®ã€‘ ğŸ”§
{sub_divider}
"""
            for tip in analysis.prompt_optimization_tips:
                report += f"â€¢ {tip}\n"

        report += f"""
{divider}
"""
        return report

    def _score_to_bar(self, score: float) -> str:
        """å°†åˆ†æ•°è½¬æ¢ä¸ºè¿›åº¦æ¡"""
        filled = int(score * 10)
        empty = 10 - filled
        bar = "â–ˆ" * filled + "â–‘" * empty
        return f"{bar} {score:.1%}"

    def format_session_summary(self, stats: Dict) -> str:
        """æ ¼å¼åŒ–ä¼šè¯æ‘˜è¦"""
        divider = "=" * 50

        summary = f"""
{divider}
åˆ›ä½œä¼šè¯æ‘˜è¦
{divider}

ä¼šè¯åç§°: {stats['session_name']}
çŠ¶æ€: {stats['status']}
åˆ›å»ºæ—¶é—´: {stats['created_at']}
è¿­ä»£æ¬¡æ•°: {stats['iteration_count']}
æ€»ç”¨æ—¶: {stats['total_time_minutes']:.1f} åˆ†é’Ÿ

å¹³å‡è¯„åˆ†: {stats['average_rating']:.1f}/10
æœ€é«˜è¯„åˆ†: {stats['best_rating']}/10
æœ€ä½³ç‰ˆæœ¬: ç¬¬ {(stats['best_iteration_index'] + 1) if stats['best_iteration_index'] is not None else 'æ— '} æ¬¡è¿­ä»£

æ”¹è¿›è¶‹åŠ¿: {self._translate_trend(stats['improvement_trend'])}
å·²ä¿å­˜æœ€ç»ˆç¨¿: {'æ˜¯' if stats['has_final_content'] else 'å¦'}

{divider}
"""
        return summary

    def _translate_trend(self, trend: str) -> str:
        """ç¿»è¯‘è¶‹åŠ¿"""
        translations = {
            "improving": "ğŸ“ˆ æŒç»­æ”¹è¿›",
            "declining": "ğŸ“‰ æœ‰æ‰€ä¸‹é™",
            "stable": "â¡ï¸ ä¿æŒç¨³å®š",
            "insufficient_data": "ğŸ“Š æ•°æ®ä¸è¶³"
        }
        return translations.get(trend, trend)


class HumanAICollaborativeWorkflow:
    """äººå·¥AIåä½œåˆ›ä½œå·¥ä½œæµ"""

    def __init__(self, novel_id: str, db_manager=None):
        self.novel_id = novel_id
        self.db_manager = db_manager or get_novel_manager(novel_id)
        self.prompt_generator = NovelPromptGenerator(novel_id)
        self.content_analyzer = ContentAnalyzer(self.db_manager)
        self.session_manager = CreationSessionManager(self.db_manager)
        self.ui_interface = UserInteractionInterface()

    async def generate_prompt_for_user(
        self,
        chapter_number: int,
        scene_type: str,
        focus_characters: List[str],
        target_length: int = 2000,
        style_preferences: Dict = None
    ) -> Tuple[str, PromptComponents]:
        """ä¸ºç”¨æˆ·ç”Ÿæˆç»“æ„åŒ–prompt"""

        # è·å–ç« èŠ‚å’Œè§’è‰²ä¿¡æ¯
        # TODO: å®ç°ä»æ•°æ®åº“è·å–ç« èŠ‚å’Œè§’è‰²ä¿¡æ¯
        chapter_info = {
            "number": chapter_number,
            "summary": f"ç¬¬{chapter_number}ç« å†…å®¹æ‘˜è¦"
        }
        character_details = []
        for char_name in focus_characters:
            character_details.append({
                "name": char_name,
                "description": f"{char_name}çš„æè¿°ä¿¡æ¯"
            })

        # ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        system_prompt = await self._generate_system_prompt(
            scene_type=scene_type,
            chapter_context=chapter_info,
            characters=character_details,
            style_preferences=style_preferences
        )

        # ç”Ÿæˆç”¨æˆ·æç¤ºè¯
        user_prompt = await self._generate_user_prompt(
            chapter_number=chapter_number,
            scene_type=scene_type,
            focus_characters=focus_characters,
            target_length=target_length,
            chapter_context=chapter_info
        )

        # è®¾ç½®å‚æ•°å»ºè®®
        temperature = style_preferences.get("temperature", 0.8) if style_preferences else 0.8

        prompt_components = PromptComponents(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            suggested_max_tokens=int(target_length * 1.5),
            suggested_temperature=temperature,
            metadata={
                "chapter_number": chapter_number,
                "scene_type": scene_type,
                "focus_characters": focus_characters
            }
        )

        # æ ¼å¼åŒ–ä¾›æ˜¾ç¤º
        formatted_prompt = self.ui_interface.format_prompt_for_display(prompt_components)

        return formatted_prompt, prompt_components

    async def analyze_user_content(
        self,
        session_id: str,
        generated_content: str,
        user_satisfaction: int = None,
        prompt_used: Optional[PromptComponents] = None
    ) -> Tuple[str, AnalysisResult]:
        """åˆ†æç”¨æˆ·æä¾›çš„ç”Ÿæˆå†…å®¹"""

        # è·å–ä¼šè¯ä¿¡æ¯
        session = await self.session_manager.get_session(session_id)
        if not session:
            raise ValueError(f"Session {session_id} not found")

        # è·å–ç›¸å…³ä¸Šä¸‹æ–‡
        # TODO: å®ç°ä»æ•°æ®åº“è·å–å°è¯´å’Œç« èŠ‚ä¿¡æ¯
        novel_info = {
            "id": session.novel_id,
            "title": "å°è¯´æ ‡é¢˜"
        }
        chapter_info = {
            "number": session.chapter_number,
            "summary": f"ç¬¬{session.chapter_number}ç« å†…å®¹æ‘˜è¦"
        }

        # æå–ç„¦ç‚¹è§’è‰²
        focus_characters = []
        if prompt_used and prompt_used.metadata:
            focus_characters = prompt_used.metadata.get("focus_characters", [])

        # æ‰§è¡Œå†…å®¹åˆ†æ
        analysis = await self.content_analyzer.comprehensive_analysis(
            content=generated_content,
            prompt_used=prompt_used,
            world_context={
                "novel_info": novel_info,
                "chapter_info": chapter_info
            },
            focus_characters=focus_characters
        )

        # æ·»åŠ åˆ°ä¼šè¯
        await self.session_manager.add_content_iteration(
            session_id=session_id,
            content=generated_content,
            user_rating=user_satisfaction or 5,
            analysis=analysis,
            prompt_used=prompt_used
        )

        # æ ¼å¼åŒ–åˆ†ææŠ¥å‘Š
        formatted_report = self.ui_interface.format_analysis_report(analysis)

        return formatted_report, analysis

    async def suggest_improvements(
        self,
        session_id: str,
        analysis_result: AnalysisResult,
        user_feedback: str = ""
    ) -> Dict[str, Any]:
        """æä¾›æ”¹è¿›å»ºè®®"""

        suggestions = {
            "prompt_improvements": [],
            "content_improvements": [],
            "next_steps": []
        }

        # åŸºäºåˆ†æç»“æœç”Ÿæˆpromptæ”¹è¿›å»ºè®®
        if analysis_result.overall_score < 0.6:
            suggestions["prompt_improvements"].append(
                "è€ƒè™‘åœ¨promptä¸­åŠ å…¥æ›´å…·ä½“çš„è¦æ±‚ï¼Œå¦‚å…·ä½“çš„åœºæ™¯ç»†èŠ‚ã€æƒ…æ„ŸåŸºè°ƒç­‰"
            )

        if not analysis_result.law_chain_accuracy["mentioned_law_chains"]:
            suggestions["prompt_improvements"].append(
                "åœ¨promptä¸­æ˜ç¡®æåŠéœ€è¦å±•ç°çš„æ³•åˆ™é“¾å…ƒç´ "
            )

        if analysis_result.dialogue_quality.get("dialogue_count", 0) < 2:
            suggestions["prompt_improvements"].append(
                "è¦æ±‚AIåŒ…å«è‡³å°‘3-4å¤„è§’è‰²å¯¹è¯ï¼Œå±•ç°è§’è‰²æ€§æ ¼"
            )

        # å†…å®¹æ”¹è¿›å»ºè®®
        suggestions["content_improvements"].extend(analysis_result.specific_suggestions)

        # ä¸‹ä¸€æ­¥å»ºè®®
        if analysis_result.overall_score > 0.8:
            suggestions["next_steps"].append("å†…å®¹è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ä¿å­˜ä¸ºæœ€ç»ˆç‰ˆæœ¬")
        elif analysis_result.overall_score > 0.6:
            suggestions["next_steps"].append("æ ¹æ®å…·ä½“å»ºè®®å¾®è°ƒpromptåé‡æ–°ç”Ÿæˆ")
        else:
            suggestions["next_steps"].append("å»ºè®®é‡æ–°è®¾è®¡promptï¼ŒåŠ å…¥æ›´å¤šå…·ä½“è¦æ±‚")

        # å¦‚æœæœ‰ç”¨æˆ·åé¦ˆï¼Œç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
        if user_feedback:
            suggestions["targeted_suggestions"] = await self._generate_targeted_suggestions(
                user_feedback,
                analysis_result
            )

        return suggestions

    async def optimize_prompt_iteration(
        self,
        session_id: str,
        original_prompt: PromptComponents,
        issues_found: List[str],
        desired_improvements: List[str]
    ) -> Tuple[str, PromptComponents]:
        """åŸºäºåé¦ˆä¼˜åŒ–prompt"""

        # åˆ†æé—®é¢˜
        optimization_focus = self._analyze_optimization_needs(
            issues_found,
            desired_improvements
        )

        # ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯
        optimized_system = original_prompt.system_prompt
        for focus in optimization_focus["system_additions"]:
            optimized_system += f"\n\n{focus}"

        # ä¿®æ”¹ç”¨æˆ·æç¤ºè¯
        optimized_user = original_prompt.user_prompt
        for focus in optimization_focus["user_additions"]:
            optimized_user += f"\n\n{focus}"

        # è°ƒæ•´å‚æ•°
        new_temperature = original_prompt.suggested_temperature
        if "æ›´æœ‰åˆ›æ„" in str(desired_improvements):
            new_temperature = min(new_temperature + 0.1, 1.0)
        elif "æ›´å‡†ç¡®" in str(desired_improvements):
            new_temperature = max(new_temperature - 0.1, 0.5)

        optimized_prompt = PromptComponents(
            system_prompt=optimized_system,
            user_prompt=optimized_user,
            suggested_max_tokens=original_prompt.suggested_max_tokens,
            suggested_temperature=new_temperature,
            metadata=original_prompt.metadata
        )

        formatted = self.ui_interface.format_prompt_for_display(optimized_prompt)

        return formatted, optimized_prompt

    async def _generate_system_prompt(
        self,
        scene_type: str,
        chapter_context: Dict,
        characters: List[Dict],
        style_preferences: Dict = None
    ) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""

        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç„å¹»å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œå¯Œæœ‰ä¸œæ–¹ç„å¹»è‰²å½©çš„ä¿®ä»™å°è¯´ã€‚

ã€ä¸–ç•Œè§‚è®¾å®šã€‘
è¿™æ˜¯ä¸€ä¸ªä»¥"æ³•åˆ™é“¾"ä¸ºæ ¸å¿ƒåŠ›é‡ä½“ç³»çš„ç„å¹»ä¸–ç•Œã€‚ä¿®ç‚¼è€…é€šè¿‡æ„Ÿæ‚Ÿå’ŒæŒæ§ä¸åŒçš„æ³•åˆ™é“¾æ¥æå‡å®åŠ›ã€‚
ä¸»è¦æ³•åˆ™é“¾åŒ…æ‹¬ï¼šæ—¶é—´ã€ç©ºé—´ã€ç”Ÿå‘½ã€æ­»äº¡ã€å› æœã€è½®å›ã€åˆ›é€ ã€æ¯ç­ã€å¹³è¡¡ã€‚

ã€åœºæ™¯ç±»å‹ã€‘
å½“å‰éœ€è¦åˆ›ä½œçš„æ˜¯ï¼š{scene_type}ç±»å‹çš„åœºæ™¯

ã€å†™ä½œé£æ ¼è¦æ±‚ã€‘
- è¯­è¨€ä¼˜ç¾æµç•…ï¼Œå¯Œæœ‰ç”»é¢æ„Ÿ
- æ³¨é‡ç»†èŠ‚æå†™å’Œæ°›å›´è¥é€ 
- äººç‰©å¯¹è¯è¦ç¬¦åˆè§’è‰²æ€§æ ¼
- åŠ¨ä½œæå†™è¦æœ‰å¼ åŠ›å’ŒèŠ‚å¥æ„Ÿ
- é€‚å½“è¿ç”¨æ¯”å–»ã€æ’æ¯”ç­‰ä¿®è¾æ‰‹æ³•"""

        if style_preferences:
            style_notes = style_preferences.get("notes", "")
            if style_notes:
                system_prompt += f"\n\nã€ç‰¹æ®Šé£æ ¼è¦æ±‚ã€‘\n{style_notes}"

        if characters:
            system_prompt += "\n\nã€é‡ç‚¹è§’è‰²ä¿¡æ¯ã€‘"
            for char in characters[:3]:  # æœ€å¤šåˆ—å‡º3ä¸ªè§’è‰²
                system_prompt += f"\n- {char.get('name', 'æœªçŸ¥')}: {char.get('description', 'æ— æè¿°')}"

        return system_prompt

    async def _generate_user_prompt(
        self,
        chapter_number: int,
        scene_type: str,
        focus_characters: List[str],
        target_length: int,
        chapter_context: Dict = None
    ) -> str:
        """ç”Ÿæˆç”¨æˆ·æç¤ºè¯"""

        user_prompt = f"""è¯·ä¸ºç¬¬{chapter_number}ç« åˆ›ä½œä¸€ä¸ª{scene_type}åœºæ™¯ã€‚

ã€åœºæ™¯è¦æ±‚ã€‘
- é‡ç‚¹è§’è‰²ï¼š{', '.join(focus_characters)}
- ç›®æ ‡å­—æ•°ï¼šçº¦{target_length}å­—
- åœºæ™¯ç±»å‹ï¼š{scene_type}

ã€å†…å®¹è¦æ±‚ã€‘
1. åœºæ™¯è¦æœ‰æ˜ç¡®çš„å¼€å§‹ã€å‘å±•å’Œç»“å°¾
2. çªå‡ºå±•ç°è§’è‰²çš„æ€§æ ¼ç‰¹ç‚¹
3. é€‚å½“åŠ å…¥æ³•åˆ™é“¾ç›¸å…³çš„æè¿°
4. åŒ…å«è‡³å°‘2-3å¤„ç²¾å½©çš„å¯¹è¯
5. æ³¨æ„ä¸å‰æ–‡çš„è¿è´¯æ€§"""

        if chapter_context:
            if "summary" in chapter_context:
                user_prompt += f"\n\nã€ç« èŠ‚èƒŒæ™¯ã€‘\n{chapter_context['summary']}"

        user_prompt += "\n\nè¯·å¼€å§‹åˆ›ä½œï¼š"

        return user_prompt

    def _analyze_optimization_needs(
        self,
        issues_found: List[str],
        desired_improvements: List[str]
    ) -> Dict[str, List[str]]:
        """åˆ†æä¼˜åŒ–éœ€æ±‚"""

        system_additions = []
        user_additions = []

        # åˆ†æé—®é¢˜å¹¶ç”Ÿæˆä¼˜åŒ–
        all_feedback = issues_found + desired_improvements
        feedback_text = " ".join(all_feedback)

        if "å¯¹è¯" in feedback_text:
            user_additions.append("ã€ç‰¹åˆ«å¼ºè°ƒã€‘è¯·ç¡®ä¿åŒ…å«3-5å¤„ç”ŸåŠ¨çš„è§’è‰²å¯¹è¯ï¼Œå±•ç°äººç‰©æ€§æ ¼")

        if "æ³•åˆ™" in feedback_text or "åŠ›é‡ä½“ç³»" in feedback_text:
            system_additions.append("ã€æ³•åˆ™é“¾æå†™æŒ‡å¯¼ã€‘æå†™æ³•åˆ™é“¾æ—¶è¦å…·ä½“å±•ç°å…¶è¡¨ç°å½¢å¼ã€å¨èƒ½å’Œä¿®ç‚¼è€…çš„æ„Ÿæ‚Ÿè¿‡ç¨‹")

        if "åœºæ™¯" in feedback_text or "æå†™" in feedback_text:
            user_additions.append("ã€åœºæ™¯è¦æ±‚ã€‘è¯·åŠ å…¥ä¸°å¯Œçš„æ„Ÿå®˜æå†™ï¼ˆè§†è§‰ã€å¬è§‰ã€è§¦è§‰ç­‰ï¼‰ï¼Œè®©åœºæ™¯æ›´åŠ ç”ŸåŠ¨ç«‹ä½“")

        if "èŠ‚å¥" in feedback_text or "ç´§å¼ " in feedback_text:
            system_additions.append("ã€èŠ‚å¥æ§åˆ¶ã€‘æ³¨æ„é€šè¿‡çŸ­å¥è¥é€ ç´§å¼ æ„Ÿï¼Œé•¿å¥å±•ç°å®å¤§åœºé¢ï¼Œå¼ å¼›æœ‰åº¦")

        if "æƒ…æ„Ÿ" in feedback_text:
            user_additions.append("ã€æƒ…æ„Ÿè¦æ±‚ã€‘æ·±å…¥åˆ»ç”»è§’è‰²çš„å†…å¿ƒæ´»åŠ¨å’Œæƒ…æ„Ÿå˜åŒ–ï¼Œè®©è¯»è€…äº§ç”Ÿå…±é¸£")

        return {
            "system_additions": system_additions,
            "user_additions": user_additions
        }

    async def _generate_targeted_suggestions(
        self,
        user_feedback: str,
        analysis_result: AnalysisResult
    ) -> List[str]:
        """ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®"""

        suggestions = []

        # æ ¹æ®ç”¨æˆ·åé¦ˆç”Ÿæˆå»ºè®®
        if "å¤ªçŸ­" in user_feedback:
            suggestions.append("å¢åŠ åœºæ™¯ç»†èŠ‚æå†™å’Œäººç‰©å¿ƒç†æ´»åŠ¨")
            suggestions.append("å¯ä»¥åŠ å…¥æ›´å¤šçš„ç¯å¢ƒæå†™å’Œæ°›å›´æ¸²æŸ“")

        if "ä¸å¤Ÿç²¾å½©" in user_feedback:
            suggestions.append("å¢åŠ å†²çªå’Œè½¬æŠ˜ï¼Œæå‡æˆå‰§å¼ åŠ›")
            suggestions.append("åŠ å…¥æ„å¤–å…ƒç´ æˆ–åè½¬ï¼Œå¢å¼ºå¸å¼•åŠ›")

        if "è§’è‰²" in user_feedback:
            suggestions.append("æ·±åŒ–è§’è‰²æ€§æ ¼åˆ»ç”»ï¼Œé€šè¿‡ç»†èŠ‚å±•ç°äººç‰©ç‰¹ç‚¹")
            suggestions.append("å¢åŠ è§’è‰²ç‹¬ç‰¹çš„è¯­è¨€é£æ ¼å’Œè¡Œä¸ºæ¨¡å¼")

        return suggestions


# å¯¼å‡ºä¸»è¦ç±»
__all__ = [
    'HumanAICollaborativeWorkflow',
    'CreationSessionManager',
    'ContentAnalyzer',
    'UserInteractionInterface',
    'PromptComponents',
    'AnalysisResult',
    'CreationSession',
    'SessionStatus',
    'ContentType'
]