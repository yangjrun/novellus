#!/usr/bin/env python3
"""
è·¨åŸŸå†²çªåˆ†æç³»ç»Ÿæ•°æ®å¯¼å…¥å·¥å…·
ç”¨äºå°†åˆ†æç»“æœå¯¼å…¥åˆ°"è£‚ä¸–ä¹åŸŸÂ·æ³•åˆ™é“¾çºªå…ƒ"æ•°æ®åº“ä¸­
"""

import asyncio
import json
import uuid
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import asyncpg
from dataclasses import dataclass

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ImportConfig:
    """å¯¼å…¥é…ç½®"""
    db_host: str = "localhost"
    db_port: int = 5432
    db_name: str = "novellus"
    db_user: str = "postgres"
    db_password: str = "postgres"

    # é¡¹ç›®ä¿¡æ¯
    project_id: str = "29c170c5-4a3e-4829-a242-74c1acb96453"
    novel_id: str = "e1fd1aa4-bde2-4c76-8cee-334e54fa47d1"

    # æ•°æ®æºè·¯å¾„
    conflict_analysis_file: str = "cross_domain_conflict_analysis_report.json"
    conflict_elements_file: str = "conflict_extraction_output/conflict_elements_structured_data.json"
    enhanced_conflict_file: str = "enhanced_conflict_output/conflict_elements_enhanced_data.json"

    # å¯¼å…¥é€‰é¡¹
    clear_existing_data: bool = False
    validate_data_integrity: bool = True
    create_backup: bool = True

class ConflictDataImporter:
    """å†²çªæ•°æ®å¯¼å…¥å™¨"""

    def __init__(self, config: ImportConfig):
        self.config = config
        self.conn: Optional[asyncpg.Connection] = None
        self.stats = {
            'matrices_imported': 0,
            'entities_imported': 0,
            'relations_imported': 0,
            'hooks_imported': 0,
            'scenarios_imported': 0,
            'network_analyses_imported': 0,
            'ai_content_imported': 0,
            'errors': []
        }

    async def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = await asyncpg.connect(
                host=self.config.db_host,
                port=self.config.db_port,
                database=self.config.db_name,
                user=self.config.db_user,
                password=self.config.db_password
            )
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    async def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.conn:
            await self.conn.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

    async def validate_project_exists(self) -> bool:
        """éªŒè¯é¡¹ç›®å’Œå°è¯´æ˜¯å¦å­˜åœ¨"""
        try:
            # æ£€æŸ¥é¡¹ç›®
            project_result = await self.conn.fetchrow(
                "SELECT id, name FROM projects WHERE id = $1",
                uuid.UUID(self.config.project_id)
            )
            if not project_result:
                logger.error(f"é¡¹ç›® {self.config.project_id} ä¸å­˜åœ¨")
                return False

            # æ£€æŸ¥å°è¯´
            novel_result = await self.conn.fetchrow(
                "SELECT id, name FROM novels WHERE id = $1",
                uuid.UUID(self.config.novel_id)
            )
            if not novel_result:
                logger.error(f"å°è¯´ {self.config.novel_id} ä¸å­˜åœ¨")
                return False

            logger.info(f"é¡¹ç›®: {project_result['name']}, å°è¯´: {novel_result['name']}")
            return True

        except Exception as e:
            logger.error(f"éªŒè¯é¡¹ç›®å°è¯´å¤±è´¥: {e}")
            return False

    async def clear_existing_conflict_data(self):
        """æ¸…é™¤ç°æœ‰å†²çªæ•°æ®"""
        if not self.config.clear_existing_data:
            return

        try:
            # æŒ‰ä¾èµ–å…³ç³»é¡ºåºåˆ é™¤
            tables_to_clear = [
                'conflict_predictions',
                'network_analysis_results',
                'ai_generated_content',
                'conflict_analysis_results',
                'conflict_story_hooks',
                'conflict_scenarios',
                'conflict_escalation_paths',
                'conflict_relations',
                'conflict_entities',
                'cross_domain_conflict_matrix'
            ]

            for table in tables_to_clear:
                result = await self.conn.execute(
                    f"DELETE FROM {table} WHERE novel_id = $1",
                    uuid.UUID(self.config.novel_id)
                )
                deleted_count = int(result.split()[-1])
                if deleted_count > 0:
                    logger.info(f"æ¸…é™¤ {table}: {deleted_count} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"æ¸…é™¤ç°æœ‰æ•°æ®å¤±è´¥: {e}")
            raise

    async def load_conflict_analysis_data(self) -> Dict[str, Any]:
        """åŠ è½½å†²çªåˆ†ææ•°æ®"""
        data_files = [
            (self.config.conflict_analysis_file, "conflict_analysis"),
            (self.config.conflict_elements_file, "conflict_elements"),
            (self.config.enhanced_conflict_file, "enhanced_elements")
        ]

        loaded_data = {}

        for file_path, data_key in data_files:
            try:
                full_path = Path(file_path)
                if not full_path.exists():
                    logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    continue

                with open(full_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    loaded_data[data_key] = data
                    logger.info(f"æˆåŠŸåŠ è½½ {data_key}: {file_path}")

            except Exception as e:
                logger.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                self.stats['errors'].append(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {file_path} - {e}")

        return loaded_data

    async def import_conflict_matrices(self, analysis_data: Dict[str, Any]) -> Dict[str, uuid.UUID]:
        """å¯¼å…¥å†²çªçŸ©é˜µæ•°æ®"""
        if 'conflict_analysis' not in analysis_data:
            logger.warning("æœªæ‰¾åˆ°å†²çªçŸ©é˜µåˆ†ææ•°æ®")
            return {}

        conflict_data = analysis_data['conflict_analysis']
        if '1. å†²çªçŸ©é˜µæ·±åº¦åˆ†æ' not in conflict_data:
            logger.warning("å†²çªçŸ©é˜µæ•°æ®æ ¼å¼ä¸æ­£ç¡®")
            return {}

        matrix_analysis = conflict_data['1. å†²çªçŸ©é˜µæ·±åº¦åˆ†æ']
        domains = ['äººåŸŸ', 'å¤©åŸŸ', 'çµåŸŸ', 'è’åŸŸ']  # å‰å››åŸŸ
        intensity_matrix = matrix_analysis.get('å¼ºåº¦çŸ©é˜µ', [])

        matrix_ids = {}

        try:
            for i, domain_a in enumerate(domains):
                for j, domain_b in enumerate(domains):
                    if i >= j:  # åªå¤„ç†ä¸Šä¸‰è§’çŸ©é˜µï¼Œé¿å…é‡å¤
                        continue

                    if i < len(intensity_matrix) and j < len(intensity_matrix[i]):
                        intensity = intensity_matrix[i][j]

                        if intensity > 0:  # åªå¯¼å…¥æœ‰å†²çªçš„åŸŸå¯¹
                            matrix_id = uuid.uuid4()

                            # åˆ›å»ºå†²çªçŸ©é˜µè®°å½•
                            await self.conn.execute("""
                                INSERT INTO cross_domain_conflict_matrix (
                                    id, novel_id, matrix_name, domain_a, domain_b, intensity,
                                    conflict_type, risk_level, status, priority,
                                    core_resources, trigger_laws, typical_scenarios, key_roles
                                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
                            """,
                                matrix_id,
                                uuid.UUID(self.config.novel_id),
                                f"{domain_a}â†”{domain_b}è·¨åŸŸå†²çª",
                                domain_a,
                                domain_b,
                                float(intensity),
                                "ç»¼åˆå†²çª",
                                min(int(intensity * 2.5), 10),  # é£é™©ç­‰çº§
                                "active",
                                min(int(intensity * 2), 10),  # ä¼˜å…ˆçº§
                                [],  # core_resources - æš‚æ—¶ä¸ºç©ºï¼Œåç»­å¡«å……
                                [],  # trigger_laws
                                [],  # typical_scenarios
                                []   # key_roles
                            )

                            matrix_ids[f"{domain_a}â†”{domain_b}"] = matrix_id
                            self.stats['matrices_imported'] += 1
                            logger.info(f"å¯¼å…¥å†²çªçŸ©é˜µ: {domain_a}â†”{domain_b}, å¼ºåº¦: {intensity}")

        except Exception as e:
            logger.error(f"å¯¼å…¥å†²çªçŸ©é˜µå¤±è´¥: {e}")
            self.stats['errors'].append(f"å†²çªçŸ©é˜µå¯¼å…¥å¤±è´¥: {e}")

        return matrix_ids

    async def import_conflict_entities(self, analysis_data: Dict[str, Any], matrix_ids: Dict[str, uuid.UUID]) -> Dict[str, uuid.UUID]:
        """å¯¼å…¥å†²çªå®ä½“æ•°æ®"""
        entity_ids = {}

        # å¤„ç†ç»“æ„åŒ–å®ä½“æ•°æ®
        for data_key in ['conflict_elements', 'enhanced_elements']:
            if data_key not in analysis_data:
                continue

            entities_data = analysis_data[data_key].get('entities', [])

            try:
                for entity in entities_data:
                    entity_id = uuid.uuid4()

                    # ç¡®å®šå…³è”çš„å†²çªçŸ©é˜µ
                    conflict_matrix_id = None
                    domains = entity.get('domains', [])
                    if len(domains) >= 2:
                        domain_pair = f"{domains[0]}â†”{domains[1]}"
                        conflict_matrix_id = matrix_ids.get(domain_pair)

                    # æ˜ å°„å®ä½“ç±»å‹
                    entity_type_mapping = {
                        'æ¨æ–­å®ä½“': 'æ ¸å¿ƒèµ„æº',
                        'æ˜ç¡®å®ä½“': 'æ ¸å¿ƒèµ„æº',
                        'å…³é”®è§’è‰²': 'å…³é”®è§’è‰²',
                        'åˆ¶åº¦æ³•æ¡': 'æ³•æ¡åˆ¶åº¦',
                        'æŠ€æœ¯å·¥è‰º': 'æŠ€æœ¯å·¥è‰º',
                        'åœ°ç†ä½ç½®': 'åœ°ç†ä½ç½®',
                        'æ–‡åŒ–ç¬¦å·': 'æ–‡åŒ–ç¬¦å·'
                    }

                    mapped_type = entity_type_mapping.get(
                        entity.get('entity_type', ''),
                        'æ ¸å¿ƒèµ„æº'
                    )

                    await self.conn.execute("""
                        INSERT INTO conflict_entities (
                            id, novel_id, conflict_matrix_id, name, entity_type, entity_subtype,
                            primary_domain, involved_domains, description, characteristics,
                            strategic_value, economic_value, symbolic_value, scarcity_level,
                            conflict_roles, dispute_intensity, confidence_score, validation_status,
                            aliases, tags, source_locations
                        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21)
                    """,
                        entity_id,
                        uuid.UUID(self.config.novel_id),
                        conflict_matrix_id,
                        entity.get('name', ''),
                        mapped_type,
                        entity.get('category', ''),
                        domains[0] if domains else None,
                        domains,
                        entity.get('description', ''),
                        json.dumps(entity.get('characteristics', {})),
                        5.0,  # é»˜è®¤æˆ˜ç•¥ä»·å€¼
                        5.0,  # é»˜è®¤ç»æµä»·å€¼
                        5.0,  # é»˜è®¤è±¡å¾ä»·å€¼
                        5.0,  # é»˜è®¤ç¨€ç¼ºæ€§
                        [],   # conflict_roles
                        5,    # é»˜è®¤äº‰è®®å¼ºåº¦
                        entity.get('confidence_score', 0.8),
                        'validated' if entity.get('confidence_score', 0) > 0.7 else 'pending',
                        entity.get('aliases', []),
                        [],   # tags
                        json.dumps({'extraction_method': entity.get('extraction_method', '')})
                    )

                    entity_ids[entity.get('name', '')] = entity_id
                    self.stats['entities_imported'] += 1

            except Exception as e:
                logger.error(f"å¯¼å…¥å®ä½“æ•°æ®å¤±è´¥ ({data_key}): {e}")
                self.stats['errors'].append(f"å®ä½“å¯¼å…¥å¤±è´¥: {e}")

        logger.info(f"æˆåŠŸå¯¼å…¥ {self.stats['entities_imported']} ä¸ªå†²çªå®ä½“")
        return entity_ids

    async def import_conflict_relations(self, analysis_data: Dict[str, Any], entity_ids: Dict[str, uuid.UUID]):
        """å¯¼å…¥å†²çªå…³ç³»æ•°æ®"""

        for data_key in ['conflict_elements', 'enhanced_elements']:
            if data_key not in analysis_data:
                continue

            relations_data = analysis_data[data_key].get('relationships', [])

            try:
                for relation in relations_data:
                    source_name = relation.get('source', '')
                    target_name = relation.get('target', '')

                    source_id = entity_ids.get(source_name)
                    target_id = entity_ids.get(target_name)

                    if not source_id or not target_id:
                        continue  # è·³è¿‡æ— æ³•æ‰¾åˆ°å®ä½“çš„å…³ç³»

                    relation_id = uuid.uuid4()

                    # æ˜ å°„å…³ç³»ç±»å‹
                    relation_type_mapping = {
                        'conflicts_with': 'å†²çª',
                        'depends_on': 'ä¾èµ–',
                        'controls': 'æ§åˆ¶',
                        'influences': 'å½±å“',
                        'competes_with': 'ç«äº‰',
                        'cooperates_with': 'åˆä½œ',
                        'threatens': 'å¨èƒ',
                        'supports': 'æ”¯æŒ'
                    }

                    mapped_type = relation_type_mapping.get(
                        relation.get('relationship_type', ''),
                        'å½±å“'
                    )

                    await self.conn.execute("""
                        INSERT INTO conflict_relations (
                            id, novel_id, source_entity_id, target_entity_id,
                            relation_type, relation_subtype, strength, directionality,
                            description, context, is_cross_domain, impact_level,
                            confidence_score, detection_method
                        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
                    """,
                        relation_id,
                        uuid.UUID(self.config.novel_id),
                        source_id,
                        target_id,
                        mapped_type,
                        relation.get('category', ''),
                        relation.get('strength', 0.5),
                        'bidirectional',
                        relation.get('description', ''),
                        relation.get('context', ''),
                        True,  # é»˜è®¤ä¸ºè·¨åŸŸå…³ç³»
                        5,     # é»˜è®¤å½±å“ç­‰çº§
                        relation.get('confidence', 0.7),
                        'automated_analysis'
                    )

                    self.stats['relations_imported'] += 1

            except Exception as e:
                logger.error(f"å¯¼å…¥å…³ç³»æ•°æ®å¤±è´¥ ({data_key}): {e}")
                self.stats['errors'].append(f"å…³ç³»å¯¼å…¥å¤±è´¥: {e}")

        logger.info(f"æˆåŠŸå¯¼å…¥ {self.stats['relations_imported']} ä¸ªå†²çªå…³ç³»")

    async def import_story_hooks(self, analysis_data: Dict[str, Any], matrix_ids: Dict[str, uuid.UUID]):
        """å¯¼å…¥å‰§æƒ…é’©å­æ•°æ®"""
        if 'conflict_analysis' not in analysis_data:
            return

        hooks_section = analysis_data['conflict_analysis'].get('4. æ™ºèƒ½å‰§æƒ…é’©å­æ¨è', {})

        # å¤„ç†ç°æœ‰å‰§æƒ…é’©å­
        existing_hooks = hooks_section.get('ç°æœ‰å‰§æƒ…é’©å­è¯„ä¼°', {})
        ai_generated_hooks = hooks_section.get('AIç”Ÿæˆæ–°é’©å­', {})

        try:
            # å¯¼å…¥ç°æœ‰å‰§æƒ…é’©å­
            for hook_key, hook_data in existing_hooks.items():
                if isinstance(hook_data, dict) and 'title' in hook_data:
                    hook_id = uuid.uuid4()

                    # ç¡®å®šç›¸å…³åŸŸå’Œå†²çªçŸ©é˜µ
                    domains = hook_data.get('domains_involved', [])
                    conflict_matrix_id = None
                    if len(domains) >= 2:
                        domain_pair = f"{domains[0]}â†”{domains[1]}"
                        conflict_matrix_id = matrix_ids.get(domain_pair)

                    await self.conn.execute("""
                        INSERT INTO conflict_story_hooks (
                            id, novel_id, conflict_matrix_id, title, description,
                            hook_type, hook_subtype, domains_involved, main_characters,
                            moral_themes, inciting_incident, originality, complexity,
                            emotional_impact, plot_integration, overall_score, priority_level,
                            is_ai_generated, tags
                        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19)
                    """,
                        hook_id,
                        uuid.UUID(self.config.novel_id),
                        conflict_matrix_id,
                        hook_data.get('title', ''),
                        hook_data.get('description', ''),
                        hook_data.get('hook_type', 'ç»¼åˆå†²çª'),
                        hook_data.get('subtype', ''),
                        domains,
                        hook_data.get('characters', []),
                        hook_data.get('themes', []),
                        hook_data.get('inciting_incident', ''),
                        hook_data.get('originality', 5),
                        hook_data.get('complexity', 5),
                        hook_data.get('emotional_impact', 5),
                        hook_data.get('plot_integration', 5),
                        hook_data.get('overall_score', 5.0),
                        hook_data.get('priority', 5),
                        False,  # ä¸æ˜¯AIç”Ÿæˆ
                        hook_data.get('tags', [])
                    )

                    self.stats['hooks_imported'] += 1

            # å¯¼å…¥AIç”Ÿæˆçš„å‰§æƒ…é’©å­
            for hook_key, hook_data in ai_generated_hooks.items():
                if isinstance(hook_data, dict) and 'title' in hook_data:
                    hook_id = uuid.uuid4()

                    domains = hook_data.get('domains_involved', [])
                    conflict_matrix_id = None
                    if len(domains) >= 2:
                        domain_pair = f"{domains[0]}â†”{domains[1]}"
                        conflict_matrix_id = matrix_ids.get(domain_pair)

                    await self.conn.execute("""
                        INSERT INTO conflict_story_hooks (
                            id, novel_id, conflict_matrix_id, title, description,
                            hook_type, hook_subtype, domains_involved, main_characters,
                            moral_themes, inciting_incident, originality, complexity,
                            emotional_impact, plot_integration, overall_score, priority_level,
                            is_ai_generated, generation_method, generation_model,
                            human_validation_status, tags
                        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22)
                    """,
                        hook_id,
                        uuid.UUID(self.config.novel_id),
                        conflict_matrix_id,
                        hook_data.get('title', ''),
                        hook_data.get('description', ''),
                        hook_data.get('hook_type', 'ç»¼åˆå†²çª'),
                        hook_data.get('subtype', ''),
                        domains,
                        hook_data.get('characters', []),
                        hook_data.get('themes', []),
                        hook_data.get('inciting_incident', ''),
                        hook_data.get('originality', 5),
                        hook_data.get('complexity', 5),
                        hook_data.get('emotional_impact', 5),
                        hook_data.get('plot_integration', 5),
                        hook_data.get('overall_score', 5.0),
                        hook_data.get('priority', 5),
                        True,   # AIç”Ÿæˆ
                        'conflict_analysis_system',
                        'claude-sonnet',
                        'pending',
                        hook_data.get('tags', [])
                    )

                    self.stats['hooks_imported'] += 1

        except Exception as e:
            logger.error(f"å¯¼å…¥å‰§æƒ…é’©å­å¤±è´¥: {e}")
            self.stats['errors'].append(f"å‰§æƒ…é’©å­å¯¼å…¥å¤±è´¥: {e}")

        logger.info(f"æˆåŠŸå¯¼å…¥ {self.stats['hooks_imported']} ä¸ªå‰§æƒ…é’©å­")

    async def import_network_analysis(self, analysis_data: Dict[str, Any], matrix_ids: Dict[str, uuid.UUID]):
        """å¯¼å…¥ç½‘ç»œåˆ†æç»“æœ"""
        if 'conflict_analysis' not in analysis_data:
            return

        network_section = analysis_data['conflict_analysis'].get('2. ç½‘ç»œæ‹“æ‰‘åˆ†æ', {})

        try:
            for analysis_key, analysis_data_item in network_section.items():
                if not isinstance(analysis_data_item, dict):
                    continue

                analysis_id = uuid.uuid4()

                # ç¡®å®šåˆ†æç±»å‹
                analysis_type_mapping = {
                    'åŸºç¡€ç½‘ç»œæŒ‡æ ‡': 'ç½‘ç»œå¯†åº¦åˆ†æ',
                    'åº¦åˆ†å¸ƒåˆ†æ': 'åº¦åˆ†å¸ƒåˆ†æ',
                    'ä¸­å¿ƒæ€§åˆ†æ': 'ä¸­å¿ƒæ€§åˆ†æ',
                    'ç¤¾å›¢æ£€æµ‹': 'ç¤¾å›¢æ£€æµ‹',
                    'è·¯å¾„åˆ†æ': 'è·¯å¾„åˆ†æ'
                }

                analysis_type = analysis_type_mapping.get(analysis_key, 'ç½‘ç»œå¯†åº¦åˆ†æ')

                await self.conn.execute("""
                    INSERT INTO network_analysis_results (
                        id, novel_id, analysis_type, network_type,
                        node_count, edge_count, network_density,
                        average_clustering_coefficient, average_path_length,
                        diameter, results, analysis_confidence
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
                """,
                    analysis_id,
                    uuid.UUID(self.config.novel_id),
                    analysis_type,
                    'å†²çªå…³ç³»ç½‘ç»œ',
                    analysis_data_item.get('èŠ‚ç‚¹æ•°', 100),
                    analysis_data_item.get('è¾¹æ•°', 2296),
                    analysis_data_item.get('ç½‘ç»œå¯†åº¦', 0.46),
                    analysis_data_item.get('å¹³å‡èšç±»ç³»æ•°', 0.72),
                    analysis_data_item.get('å¹³å‡è·¯å¾„é•¿åº¦', 2.1),
                    analysis_data_item.get('ç½‘ç»œç›´å¾„', 4),
                    json.dumps(analysis_data_item),
                    0.85
                )

                self.stats['network_analyses_imported'] += 1

        except Exception as e:
            logger.error(f"å¯¼å…¥ç½‘ç»œåˆ†æå¤±è´¥: {e}")
            self.stats['errors'].append(f"ç½‘ç»œåˆ†æå¯¼å…¥å¤±è´¥: {e}")

        logger.info(f"æˆåŠŸå¯¼å…¥ {self.stats['network_analyses_imported']} ä¸ªç½‘ç»œåˆ†æç»“æœ")

    async def run_import(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®å¯¼å…¥æµç¨‹"""
        start_time = datetime.now()

        try:
            # 1. è¿æ¥æ•°æ®åº“
            await self.connect()

            # 2. éªŒè¯é¡¹ç›®å­˜åœ¨
            if not await self.validate_project_exists():
                raise Exception("é¡¹ç›®éªŒè¯å¤±è´¥")

            # 3. æ¸…é™¤ç°æœ‰æ•°æ®ï¼ˆå¦‚æœé…ç½®å…è®¸ï¼‰
            await self.clear_existing_conflict_data()

            # 4. åŠ è½½åˆ†ææ•°æ®
            logger.info("å¼€å§‹åŠ è½½åˆ†ææ•°æ®...")
            analysis_data = await self.load_conflict_analysis_data()

            if not analysis_data:
                raise Exception("æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•åˆ†ææ•°æ®")

            # 5. å¯¼å…¥å†²çªçŸ©é˜µ
            logger.info("å¼€å§‹å¯¼å…¥å†²çªçŸ©é˜µ...")
            matrix_ids = await self.import_conflict_matrices(analysis_data)

            # 6. å¯¼å…¥å†²çªå®ä½“
            logger.info("å¼€å§‹å¯¼å…¥å†²çªå®ä½“...")
            entity_ids = await self.import_conflict_entities(analysis_data, matrix_ids)

            # 7. å¯¼å…¥å†²çªå…³ç³»
            logger.info("å¼€å§‹å¯¼å…¥å†²çªå…³ç³»...")
            await self.import_conflict_relations(analysis_data, entity_ids)

            # 8. å¯¼å…¥å‰§æƒ…é’©å­
            logger.info("å¼€å§‹å¯¼å…¥å‰§æƒ…é’©å­...")
            await self.import_story_hooks(analysis_data, matrix_ids)

            # 9. å¯¼å…¥ç½‘ç»œåˆ†æç»“æœ
            logger.info("å¼€å§‹å¯¼å…¥ç½‘ç»œåˆ†æç»“æœ...")
            await self.import_network_analysis(analysis_data, matrix_ids)

            # 10. è®¡ç®—å¯¼å…¥ç»Ÿè®¡
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            result = {
                'success': True,
                'duration_seconds': duration,
                'statistics': self.stats,
                'summary': {
                    'total_imported': (
                        self.stats['matrices_imported'] +
                        self.stats['entities_imported'] +
                        self.stats['relations_imported'] +
                        self.stats['hooks_imported'] +
                        self.stats['network_analyses_imported']
                    ),
                    'errors_count': len(self.stats['errors'])
                }
            }

            logger.info(f"æ•°æ®å¯¼å…¥å®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’")
            logger.info(f"å¯¼å…¥ç»Ÿè®¡: {result['summary']}")

            return result

        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'statistics': self.stats
            }

        finally:
            await self.disconnect()

async def main():
    """ä¸»å‡½æ•°"""
    config = ImportConfig()
    importer = ConflictDataImporter(config)

    result = await importer.run_import()

    if result['success']:
        print("\nâœ… æ•°æ®å¯¼å…¥æˆåŠŸå®Œæˆ!")
        print(f"ğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
        print(f"   - å†²çªçŸ©é˜µ: {result['statistics']['matrices_imported']}")
        print(f"   - å†²çªå®ä½“: {result['statistics']['entities_imported']}")
        print(f"   - å†²çªå…³ç³»: {result['statistics']['relations_imported']}")
        print(f"   - å‰§æƒ…é’©å­: {result['statistics']['hooks_imported']}")
        print(f"   - ç½‘ç»œåˆ†æ: {result['statistics']['network_analyses_imported']}")
        print(f"â±ï¸  æ€»è€—æ—¶: {result['duration_seconds']:.2f} ç§’")

        if result['statistics']['errors']:
            print(f"\nâš ï¸  å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç° {len(result['statistics']['errors'])} ä¸ªé”™è¯¯:")
            for error in result['statistics']['errors']:
                print(f"   - {error}")
    else:
        print(f"\nâŒ æ•°æ®å¯¼å…¥å¤±è´¥: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())