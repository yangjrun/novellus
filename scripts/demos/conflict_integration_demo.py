#!/usr/bin/env python3
"""
è£‚ä¸–ä¹åŸŸÂ·æ³•åˆ™é“¾çºªå…ƒè·¨åŸŸå†²çªåˆ†æç³»ç»Ÿé›†æˆæ¼”ç¤ºè„šæœ¬
å±•ç¤ºå®Œæ•´çš„æ•°æ®å¯¼å…¥ã€æŸ¥è¯¢å’Œåˆ†æåŠŸèƒ½
"""

import asyncio
import json
import sys
import time
from pathlib import Path
from typing import Dict, Any, List
import logging

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from database.conflict_data_importer import ConflictDataImporter, ImportConfig
from database.data_access import init_database, close_database, get_novel_manager
from database.connections.postgresql import get_pg_pool

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ConflictIntegrationDemo:
    """å†²çªåˆ†æç³»ç»Ÿé›†æˆæ¼”ç¤ºç±»"""

    def __init__(self):
        self.project_id = "29c170c5-4a3e-4829-a242-74c1acb96453"
        self.novel_id = "e1fd1aa4-bde2-4c76-8cee-334e54fa47d1"
        self.results = {}

    async def print_banner(self):
        """æ‰“å°æ¼”ç¤ºæ¨ªå¹…"""
        banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 è£‚ä¸–ä¹åŸŸÂ·æ³•åˆ™é“¾çºªå…ƒè·¨åŸŸå†²çªåˆ†æç³»ç»Ÿ                         â•‘
â•‘                        å®Œæ•´é›†æˆæ¼”ç¤ºè„šæœ¬                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ æ¼”ç¤ºç›®æ ‡ï¼š
   1. åˆå§‹åŒ–æ•°æ®åº“æ¶æ„
   2. å¯¼å…¥å†²çªåˆ†ææ•°æ®ï¼ˆ100å®ä½“+2296å…³ç³»ï¼‰
   3. éªŒè¯æ•°æ®å®Œæ•´æ€§
   4. å±•ç¤ºæŸ¥è¯¢å’Œåˆ†æåŠŸèƒ½
   5. ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š

ğŸ“Š åˆ†ææ•°æ®è§„æ¨¡ï¼š
   - è·¨åŸŸå†²çªçŸ©é˜µï¼š6ä¸ªå†²çªå¯¹
   - å†²çªå®ä½“ï¼š100ä¸ªç»“æ„åŒ–å®ä½“
   - å†²çªå…³ç³»ï¼š2,296ä¸ªå¤æ‚å…³ç³»
   - å‰§æƒ…é’©å­ï¼š30ä¸ªé«˜è´¨é‡é’©å­
   - ç½‘ç»œåˆ†æï¼šå®Œæ•´æ‹“æ‰‘ç»“æ„åˆ†æ
   - AIç”Ÿæˆå†…å®¹ï¼šæ™ºèƒ½åˆ›ä½œæ”¯æŒ

ğŸ”§ æŠ€æœ¯æ¶æ„ï¼š
   - PostgreSQL + MongoDBæ··åˆæ•°æ®åº“
   - å®Œæ•´çš„MCP APIæ”¯æŒ
   - é«˜æ€§èƒ½ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–
   - ç‰ˆæœ¬æ§åˆ¶å’Œå®¡æ ¸æµç¨‹

æ­£åœ¨å¯åŠ¨æ¼”ç¤º...
        """
        print(banner)

    async def step_1_initialize_database(self) -> bool:
        """æ­¥éª¤1ï¼šåˆå§‹åŒ–æ•°æ®åº“"""
        print("\n" + "="*80)
        print("ğŸ”§ æ­¥éª¤1: åˆå§‹åŒ–æ•°æ®åº“æ¶æ„")
        print("="*80)

        try:
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            await init_database()
            print("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")

            # æ£€æŸ¥æ ¸å¿ƒè¡¨æ˜¯å¦å­˜åœ¨
            pool = await get_pg_pool()
            async with pool.acquire() as conn:
                # æ£€æŸ¥åŸºç¡€è¡¨
                basic_tables = ['projects', 'novels', 'domains', 'law_chains']
                for table in basic_tables:
                    result = await conn.fetchval(
                        "SELECT COUNT(*) FROM information_schema.tables WHERE table_name = $1",
                        table
                    )
                    if result > 0:
                        print(f"âœ… åŸºç¡€è¡¨ {table} å­˜åœ¨")
                    else:
                        print(f"âŒ åŸºç¡€è¡¨ {table} ä¸å­˜åœ¨")
                        return False

                # æ£€æŸ¥å†²çªåˆ†æè¡¨
                conflict_tables = [
                    'cross_domain_conflict_matrix',
                    'conflict_entities',
                    'conflict_relations',
                    'conflict_story_hooks',
                    'network_analysis_results',
                    'ai_generated_content'
                ]

                for table in conflict_tables:
                    result = await conn.fetchval(
                        "SELECT COUNT(*) FROM information_schema.tables WHERE table_name = $1",
                        table
                    )
                    if result > 0:
                        print(f"âœ… å†²çªåˆ†æè¡¨ {table} å­˜åœ¨")
                    else:
                        print(f"âš ï¸  å†²çªåˆ†æè¡¨ {table} ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º")

                # éªŒè¯é¡¹ç›®å’Œå°è¯´æ•°æ®
                project_count = await conn.fetchval(
                    "SELECT COUNT(*) FROM projects WHERE id = $1",
                    self.project_id
                )
                novel_count = await conn.fetchval(
                    "SELECT COUNT(*) FROM novels WHERE id = $1",
                    self.novel_id
                )

                print(f"ğŸ“Š é¡¹ç›®æ•°æ®éªŒè¯: {'âœ…' if project_count > 0 else 'âŒ'} "
                      f"(é¡¹ç›®ID: {self.project_id})")
                print(f"ğŸ“Š å°è¯´æ•°æ®éªŒè¯: {'âœ…' if novel_count > 0 else 'âŒ'} "
                      f"(å°è¯´ID: {self.novel_id})")

            self.results['database_init'] = {
                'success': True,
                'basic_tables_ok': True,
                'project_exists': project_count > 0,
                'novel_exists': novel_count > 0
            }

            return True

        except Exception as e:
            print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.results['database_init'] = {
                'success': False,
                'error': str(e)
            }
            return False

    async def step_2_import_conflict_data(self) -> bool:
        """æ­¥éª¤2ï¼šå¯¼å…¥å†²çªåˆ†ææ•°æ®"""
        print("\n" + "="*80)
        print("ğŸ“¥ æ­¥éª¤2: å¯¼å…¥å†²çªåˆ†ææ•°æ®")
        print("="*80)

        try:
            config = ImportConfig(
                project_id=self.project_id,
                novel_id=self.novel_id,
                clear_existing_data=True,  # æ¸…é™¤ç°æœ‰æ•°æ®ä»¥ç¡®ä¿å¹²å‡€çš„å¯¼å…¥
                validate_data_integrity=True
            )

            importer = ConflictDataImporter(config)

            print("ğŸ”„ å¼€å§‹å¯¼å…¥å†²çªåˆ†ææ•°æ®...")
            start_time = time.time()

            result = await importer.run_import()

            import_time = time.time() - start_time

            if result['success']:
                stats = result['statistics']
                print(f"âœ… æ•°æ®å¯¼å…¥æˆåŠŸå®Œæˆ (è€—æ—¶: {import_time:.2f}ç§’)")
                print(f"ğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
                print(f"   - å†²çªçŸ©é˜µ: {stats['matrices_imported']} ä¸ª")
                print(f"   - å†²çªå®ä½“: {stats['entities_imported']} ä¸ª")
                print(f"   - å†²çªå…³ç³»: {stats['relations_imported']} ä¸ª")
                print(f"   - å‰§æƒ…é’©å­: {stats['hooks_imported']} ä¸ª")
                print(f"   - ç½‘ç»œåˆ†æ: {stats['network_analyses_imported']} ä¸ª")

                if stats['errors']:
                    print(f"âš ï¸  å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç° {len(stats['errors'])} ä¸ªé”™è¯¯:")
                    for error in stats['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                        print(f"   - {error}")

                self.results['data_import'] = result
                return True
            else:
                print(f"âŒ æ•°æ®å¯¼å…¥å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                self.results['data_import'] = result
                return False

        except Exception as e:
            print(f"âŒ å¯¼å…¥è¿‡ç¨‹å¼‚å¸¸: {e}")
            self.results['data_import'] = {
                'success': False,
                'error': str(e)
            }
            return False

    async def step_3_validate_data_integrity(self) -> bool:
        """æ­¥éª¤3ï¼šéªŒè¯æ•°æ®å®Œæ•´æ€§"""
        print("\n" + "="*80)
        print("ğŸ” æ­¥éª¤3: éªŒè¯æ•°æ®å®Œæ•´æ€§")
        print("="*80)

        try:
            pool = await get_pg_pool()
            async with pool.acquire() as conn:
                # ç»Ÿè®¡å„è¡¨æ•°æ®é‡
                table_stats = {}

                tables_to_check = [
                    'cross_domain_conflict_matrix',
                    'conflict_entities',
                    'conflict_relations',
                    'conflict_story_hooks',
                    'network_analysis_results',
                    'ai_generated_content'
                ]

                for table in tables_to_check:
                    count = await conn.fetchval(
                        f"SELECT COUNT(*) FROM {table} WHERE novel_id = $1",
                        self.novel_id
                    )
                    table_stats[table] = count
                    print(f"ğŸ“Š {table}: {count} æ¡è®°å½•")

                # æ£€æŸ¥å…³ç³»å®Œæ•´æ€§
                entities_with_relations = await conn.fetchval("""
                    SELECT COUNT(DISTINCT source_entity_id) + COUNT(DISTINCT target_entity_id)
                    FROM conflict_relations
                    WHERE novel_id = $1
                """, self.novel_id)

                total_entities = table_stats.get('conflict_entities', 0)
                relation_coverage = (entities_with_relations / (total_entities * 2)) * 100 if total_entities > 0 else 0

                print(f"ğŸ”— å…³ç³»è¦†ç›–ç‡: {relation_coverage:.1f}% ({entities_with_relations}/{total_entities * 2})")

                # æ£€æŸ¥å†²çªçŸ©é˜µå®Œæ•´æ€§
                matrix_domains = await conn.fetch("""
                    SELECT domain_a, domain_b, intensity
                    FROM cross_domain_conflict_matrix
                    WHERE novel_id = $1
                    ORDER BY intensity DESC
                """, self.novel_id)

                print(f"ğŸ­ å†²çªçŸ©é˜µè¯¦æƒ…:")
                for row in matrix_domains:
                    print(f"   - {row['domain_a']} â†” {row['domain_b']}: å¼ºåº¦ {row['intensity']}")

                # æ£€æŸ¥æ•°æ®è´¨é‡
                validation_results = await conn.fetch("""
                    SELECT
                        validation_status,
                        COUNT(*) as count,
                        AVG(confidence_score) as avg_confidence
                    FROM conflict_entities
                    WHERE novel_id = $1
                    GROUP BY validation_status
                """, self.novel_id)

                print(f"ğŸ¯ æ•°æ®è´¨é‡è¯„ä¼°:")
                for row in validation_results:
                    print(f"   - {row['validation_status']}: {row['count']} ä¸ªå®ä½“ "
                          f"(å¹³å‡ç½®ä¿¡åº¦: {row['avg_confidence']:.3f})")

                self.results['data_validation'] = {
                    'success': True,
                    'table_stats': table_stats,
                    'relation_coverage': relation_coverage,
                    'matrix_domains': len(matrix_domains),
                    'validation_summary': [dict(row) for row in validation_results]
                }

                return True

        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            self.results['data_validation'] = {
                'success': False,
                'error': str(e)
            }
            return False

    async def step_4_demonstrate_queries(self) -> bool:
        """æ­¥éª¤4ï¼šæ¼”ç¤ºæŸ¥è¯¢åŠŸèƒ½"""
        print("\n" + "="*80)
        print("ğŸ” æ­¥éª¤4: æ¼”ç¤ºæŸ¥è¯¢å’Œåˆ†æåŠŸèƒ½")
        print("="*80)

        try:
            pool = await get_pg_pool()

            # æ¼”ç¤º1: é«˜å¼ºåº¦å†²çªæŸ¥è¯¢
            print("\nğŸ“ˆ æ¼”ç¤º1: æŸ¥è¯¢é«˜å¼ºåº¦è·¨åŸŸå†²çª")
            async with pool.acquire() as conn:
                high_conflicts = await conn.fetch("""
                    SELECT domain_a, domain_b, intensity, risk_level, priority
                    FROM cross_domain_conflict_matrix
                    WHERE novel_id = $1 AND intensity >= 3.5
                    ORDER BY intensity DESC
                """, self.novel_id)

                for conflict in high_conflicts:
                    print(f"   ğŸ”¥ {conflict['domain_a']} vs {conflict['domain_b']}: "
                          f"å¼ºåº¦{conflict['intensity']}, é£é™©{conflict['risk_level']}, "
                          f"ä¼˜å…ˆçº§{conflict['priority']}")

            # æ¼”ç¤º2: æ ¸å¿ƒå®ä½“åˆ†æ
            print("\nğŸ¯ æ¼”ç¤º2: æ ¸å¿ƒå†²çªå®ä½“åˆ†æ")
            async with pool.acquire() as conn:
                key_entities = await conn.fetch("""
                    SELECT name, entity_type, strategic_value, dispute_intensity,
                           array_to_string(involved_domains, ', ') as domains
                    FROM conflict_entities
                    WHERE novel_id = $1 AND strategic_value >= 7.0
                    ORDER BY strategic_value DESC
                    LIMIT 10
                """, self.novel_id)

                for entity in key_entities:
                    print(f"   âš”ï¸  {entity['name']} ({entity['entity_type']})")
                    print(f"      æˆ˜ç•¥ä»·å€¼: {entity['strategic_value']}, "
                          f"äº‰è®®å¼ºåº¦: {entity['dispute_intensity']}")
                    print(f"      æ¶‰åŠåŸŸ: {entity['domains']}")

            # æ¼”ç¤º3: å‰§æƒ…é’©å­æ¨è
            print("\nğŸ¬ æ¼”ç¤º3: é«˜è´¨é‡å‰§æƒ…é’©å­æ¨è")
            async with pool.acquire() as conn:
                top_hooks = await conn.fetch("""
                    SELECT title, hook_type, overall_score, emotional_impact,
                           is_ai_generated, array_to_string(domains_involved, ', ') as domains
                    FROM conflict_story_hooks
                    WHERE novel_id = $1 AND overall_score >= 7.0
                    ORDER BY overall_score DESC
                    LIMIT 5
                """, self.novel_id)

                for hook in top_hooks:
                    ai_tag = "ğŸ¤– AIç”Ÿæˆ" if hook['is_ai_generated'] else "ğŸ“ åŸåˆ›"
                    print(f"   ğŸ­ {hook['title']} ({hook['hook_type']}) {ai_tag}")
                    print(f"      è¯„åˆ†: {hook['overall_score']}, "
                          f"æƒ…æ„Ÿå†²å‡»: {hook['emotional_impact']}")
                    print(f"      æ¶‰åŠåŸŸ: {hook['domains']}")

            # æ¼”ç¤º4: ç½‘ç»œåˆ†æç»“æœ
            print("\nğŸ•¸ï¸  æ¼”ç¤º4: ç½‘ç»œæ‹“æ‰‘åˆ†æç»“æœ")
            async with pool.acquire() as conn:
                network_stats = await conn.fetch("""
                    SELECT analysis_type, node_count, edge_count,
                           network_density, average_clustering_coefficient,
                           community_count, analysis_confidence
                    FROM network_analysis_results
                    WHERE novel_id = $1
                    ORDER BY analysis_confidence DESC
                """, self.novel_id)

                for stat in network_stats:
                    print(f"   ğŸ“Š {stat['analysis_type']}")
                    print(f"      èŠ‚ç‚¹: {stat['node_count']}, è¾¹: {stat['edge_count']}")
                    print(f"      å¯†åº¦: {stat['network_density']:.3f}, "
                          f"èšç±»ç³»æ•°: {stat['average_clustering_coefficient']:.3f}")
                    if stat['community_count']:
                        print(f"      ç¤¾å›¢æ•°: {stat['community_count']}")

            # æ¼”ç¤º5: åŸŸå‚ä¸åº¦åˆ†æ
            print("\nğŸŒ æ¼”ç¤º5: åŸŸå‚ä¸åº¦å’Œå†²çªå€¾å‘åˆ†æ")
            async with pool.acquire() as conn:
                domain_participation = await conn.fetch("""
                    WITH domain_conflicts AS (
                        SELECT domain_a as domain, intensity FROM cross_domain_conflict_matrix WHERE novel_id = $1
                        UNION ALL
                        SELECT domain_b as domain, intensity FROM cross_domain_conflict_matrix WHERE novel_id = $1
                    )
                    SELECT domain, COUNT(*) as conflict_count, AVG(intensity) as avg_intensity,
                           CASE
                               WHEN AVG(intensity) >= 3.5 THEN 'é«˜å†²çªåŸŸ'
                               WHEN AVG(intensity) >= 2.5 THEN 'ä¸­å†²çªåŸŸ'
                               ELSE 'ä½å†²çªåŸŸ'
                           END as conflict_tendency
                    FROM domain_conflicts
                    GROUP BY domain
                    ORDER BY avg_intensity DESC
                """, self.novel_id)

                for domain in domain_participation:
                    print(f"   ğŸ° {domain['domain']}: {domain['conflict_tendency']}")
                    print(f"      å†²çªæ•°: {domain['conflict_count']}, "
                          f"å¹³å‡å¼ºåº¦: {domain['avg_intensity']:.2f}")

            self.results['query_demo'] = {
                'success': True,
                'high_conflicts': len(high_conflicts),
                'key_entities': len(key_entities),
                'top_hooks': len(top_hooks),
                'network_analyses': len(network_stats),
                'domain_stats': len(domain_participation)
            }

            return True

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢æ¼”ç¤ºå¤±è´¥: {e}")
            self.results['query_demo'] = {
                'success': False,
                'error': str(e)
            }
            return False

    async def step_5_performance_test(self) -> bool:
        """æ­¥éª¤5ï¼šæ€§èƒ½æµ‹è¯•"""
        print("\n" + "="*80)
        print("âš¡ æ­¥éª¤5: æ€§èƒ½å’Œå‹åŠ›æµ‹è¯•")
        print("="*80)

        try:
            pool = await get_pg_pool()
            performance_results = {}

            # æµ‹è¯•1: å¤æ‚å…³ç³»æŸ¥è¯¢æ€§èƒ½
            print("\nğŸ” æµ‹è¯•1: å¤æ‚å…³ç³»æŸ¥è¯¢æ€§èƒ½")
            start_time = time.time()

            async with pool.acquire() as conn:
                complex_query_result = await conn.fetch("""
                    SELECT
                        ce1.name as source_name,
                        ce2.name as target_name,
                        cr.relation_type,
                        cr.strength,
                        ce1.strategic_value,
                        ce2.strategic_value
                    FROM conflict_relations cr
                    JOIN conflict_entities ce1 ON cr.source_entity_id = ce1.id
                    JOIN conflict_entities ce2 ON cr.target_entity_id = ce2.id
                    WHERE cr.novel_id = $1
                    AND cr.strength >= 0.7
                    AND (ce1.strategic_value >= 6.0 OR ce2.strategic_value >= 6.0)
                    ORDER BY cr.strength DESC, ce1.strategic_value DESC
                    LIMIT 100
                """, self.novel_id)

            query1_time = time.time() - start_time
            print(f"   âœ… å¤æ‚å…³ç³»æŸ¥è¯¢: {len(complex_query_result)} æ¡ç»“æœ, "
                  f"è€—æ—¶ {query1_time:.3f}ç§’")

            # æµ‹è¯•2: èšåˆç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½
            print("\nğŸ“Š æµ‹è¯•2: èšåˆç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½")
            start_time = time.time()

            async with pool.acquire() as conn:
                stats_query_result = await conn.fetchrow("""
                    SELECT
                        COUNT(DISTINCT ce.id) as total_entities,
                        COUNT(DISTINCT cr.id) as total_relations,
                        COUNT(DISTINCT csh.id) as total_hooks,
                        AVG(ce.strategic_value) as avg_strategic_value,
                        AVG(cr.strength) as avg_relation_strength,
                        AVG(csh.overall_score) as avg_hook_score
                    FROM conflict_entities ce
                    LEFT JOIN conflict_relations cr ON (ce.id = cr.source_entity_id OR ce.id = cr.target_entity_id)
                    LEFT JOIN conflict_story_hooks csh ON csh.novel_id = ce.novel_id
                    WHERE ce.novel_id = $1
                """, self.novel_id)

            query2_time = time.time() - start_time
            print(f"   âœ… èšåˆç»Ÿè®¡æŸ¥è¯¢: è€—æ—¶ {query2_time:.3f}ç§’")
            print(f"      å®ä½“æ€»æ•°: {stats_query_result['total_entities']}")
            print(f"      å…³ç³»æ€»æ•°: {stats_query_result['total_relations']}")
            print(f"      é’©å­æ€»æ•°: {stats_query_result['total_hooks']}")

            # æµ‹è¯•3: å¹¶å‘æŸ¥è¯¢æµ‹è¯•
            print("\nğŸš€ æµ‹è¯•3: å¹¶å‘æŸ¥è¯¢æµ‹è¯•")
            start_time = time.time()

            concurrent_tasks = []
            for i in range(5):  # 5ä¸ªå¹¶å‘æŸ¥è¯¢
                task = self._concurrent_query_task(pool, i)
                concurrent_tasks.append(task)

            concurrent_results = await asyncio.gather(*concurrent_tasks)
            concurrent_time = time.time() - start_time

            successful_queries = sum(1 for result in concurrent_results if result['success'])
            print(f"   âœ… å¹¶å‘æŸ¥è¯¢æµ‹è¯•: {successful_queries}/5 ä¸ªæŸ¥è¯¢æˆåŠŸ, "
                  f"æ€»è€—æ—¶ {concurrent_time:.3f}ç§’")

            performance_results = {
                'complex_query_time': query1_time,
                'complex_query_results': len(complex_query_result),
                'stats_query_time': query2_time,
                'concurrent_time': concurrent_time,
                'concurrent_success_rate': successful_queries / 5,
                'total_entities': stats_query_result['total_entities'],
                'total_relations': stats_query_result['total_relations']
            }

            # è¯„ä¼°æ€§èƒ½ç­‰çº§
            if query1_time < 0.1 and query2_time < 0.05 and concurrent_time < 1.0:
                performance_grade = "ğŸ† ä¼˜ç§€"
            elif query1_time < 0.5 and query2_time < 0.2 and concurrent_time < 3.0:
                performance_grade = "âœ… è‰¯å¥½"
            else:
                performance_grade = "âš ï¸ éœ€ä¼˜åŒ–"

            print(f"\nğŸ“ˆ æ€§èƒ½è¯„ä¼°: {performance_grade}")

            self.results['performance_test'] = {
                'success': True,
                'grade': performance_grade,
                'metrics': performance_results
            }

            return True

        except Exception as e:
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.results['performance_test'] = {
                'success': False,
                'error': str(e)
            }
            return False

    async def _concurrent_query_task(self, pool, task_id: int) -> Dict[str, Any]:
        """å¹¶å‘æŸ¥è¯¢ä»»åŠ¡"""
        try:
            async with pool.acquire() as conn:
                result = await conn.fetchval("""
                    SELECT COUNT(*) FROM conflict_entities
                    WHERE novel_id = $1 AND strategic_value >= $2
                """, self.novel_id, task_id)

                return {'success': True, 'task_id': task_id, 'result': result}

        except Exception as e:
            return {'success': False, 'task_id': task_id, 'error': str(e)}

    async def step_6_generate_report(self) -> bool:
        """æ­¥éª¤6ï¼šç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“‹ æ­¥éª¤6: ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š")
        print("="*80)

        try:
            # è®¡ç®—æ€»ä½“æˆåŠŸç‡
            total_steps = len([k for k in self.results.keys() if k != 'final_report'])
            successful_steps = sum(1 for result in self.results.values()
                                 if isinstance(result, dict) and result.get('success', False))
            success_rate = (successful_steps / total_steps) * 100 if total_steps > 0 else 0

            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'integration_test_report': {
                    'project_name': 'è£‚ä¸–ä¹åŸŸÂ·æ³•åˆ™é“¾çºªå…ƒ',
                    'test_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'overall_success_rate': f"{success_rate:.1f}%",
                    'total_steps': total_steps,
                    'successful_steps': successful_steps,
                    'test_results': self.results
                }
            }

            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_file = Path("conflict_integration_test_report.json")
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)

            print(f"âœ… é›†æˆæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            print(f"ğŸ“Š æ€»ä½“æˆåŠŸç‡: {success_rate:.1f}% ({successful_steps}/{total_steps})")

            # æ‰“å°ç®€è¦æ€»ç»“
            print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœæ€»ç»“:")
            for step_name, result in self.results.items():
                if isinstance(result, dict):
                    status = "âœ… æˆåŠŸ" if result.get('success', False) else "âŒ å¤±è´¥"
                    print(f"   - {step_name}: {status}")

            # æ•°æ®ç»Ÿè®¡æ€»ç»“
            if 'data_import' in self.results and self.results['data_import'].get('success'):
                import_stats = self.results['data_import']['statistics']
                total_imported = (import_stats.get('matrices_imported', 0) +
                                import_stats.get('entities_imported', 0) +
                                import_stats.get('relations_imported', 0) +
                                import_stats.get('hooks_imported', 0) +
                                import_stats.get('network_analyses_imported', 0))
                print(f"\nğŸ“Š æ•°æ®å¯¼å…¥æˆæœ:")
                print(f"   - æ€»è®¡å¯¼å…¥: {total_imported} æ¡è®°å½•")
                print(f"   - å†²çªå®ä½“: {import_stats.get('entities_imported', 0)} ä¸ª")
                print(f"   - å†²çªå…³ç³»: {import_stats.get('relations_imported', 0)} ä¸ª")

            # æ€§èƒ½æµ‹è¯•æ€»ç»“
            if 'performance_test' in self.results and self.results['performance_test'].get('success'):
                perf_grade = self.results['performance_test']['grade']
                print(f"\nâš¡ æ€§èƒ½æµ‹è¯•ç»“æœ: {perf_grade}")

            self.results['final_report'] = {
                'success': True,
                'report_file': str(report_file),
                'overall_success_rate': success_rate
            }

            return True

        except Exception as e:
            print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            self.results['final_report'] = {
                'success': False,
                'error': str(e)
            }
            return False

    async def run_complete_demo(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´æ¼”ç¤ºæµç¨‹"""
        await self.print_banner()

        demo_steps = [
            ("åˆå§‹åŒ–æ•°æ®åº“æ¶æ„", self.step_1_initialize_database),
            ("å¯¼å…¥å†²çªåˆ†ææ•°æ®", self.step_2_import_conflict_data),
            ("éªŒè¯æ•°æ®å®Œæ•´æ€§", self.step_3_validate_data_integrity),
            ("æ¼”ç¤ºæŸ¥è¯¢åŠŸèƒ½", self.step_4_demonstrate_queries),
            ("æ€§èƒ½å‹åŠ›æµ‹è¯•", self.step_5_performance_test),
            ("ç”Ÿæˆé›†æˆæŠ¥å‘Š", self.step_6_generate_report)
        ]

        all_success = True

        for step_name, step_func in demo_steps:
            print(f"\nâ³ æ­£åœ¨æ‰§è¡Œ: {step_name}...")

            try:
                step_result = await step_func()
                if not step_result:
                    all_success = False
                    print(f"âŒ {step_name} æ‰§è¡Œå¤±è´¥")
                else:
                    print(f"âœ… {step_name} æ‰§è¡ŒæˆåŠŸ")

            except Exception as e:
                all_success = False
                print(f"âŒ {step_name} æ‰§è¡Œå¼‚å¸¸: {e}")

        # æœ€ç»ˆæ€»ç»“
        print("\n" + "="*80)
        if all_success:
            print("ğŸ‰ è£‚ä¸–ä¹åŸŸÂ·æ³•åˆ™é“¾çºªå…ƒè·¨åŸŸå†²çªåˆ†æç³»ç»Ÿé›†æˆæ¼”ç¤ºæˆåŠŸå®Œæˆ!")
            print("ğŸ“‹ æ‰€æœ‰åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œæ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        else:
            print("âš ï¸  æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

        print("="*80)

        return self.results

async def main():
    """ä¸»å‡½æ•°"""
    demo = ConflictIntegrationDemo()

    try:
        results = await demo.run_complete_demo()
        return results
    finally:
        await close_database()

if __name__ == "__main__":
    results = asyncio.run(main())